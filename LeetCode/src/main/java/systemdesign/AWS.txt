----------------Introduction
Distractor services?
	There are many services in course which are distractors
	There are over 200 AWS services and not all can be covered
	Re-invent AWS conference
---------------------Section 3------------------------------------------------------------------------------------------------
Cloud computing is the on demand delivery of compute power, database storage, applications, and other IT resources.
Through a cloud services platform with a pay as you go compute pricing
Can provision exactly the right type and size of computing resources you need
You can access as many resources instantly

#Deployment models for cloud
	Private cloud-> Cloud services used by a single organization not exposed to the public(managed by someone else)
	Complete control
	Security for sensitive applications
#Public Cloud
	Cloud services owned and operated by a third party cloud service provider delivered over the internet
#Hybrid Cloud
		Some servers on premises
		Some on third party cloud
		Sensitive data on prem, flexibility and cost effectiveness of public cloud
#FiveCharacteristics
		On Demand Self Service
		Broad network access
		Multitenancy and resource sharing
		Rapid elasticity and scalability
		Measured Service -> pay as you use
#SixAdvantages
	Trade Capex for Opex
	Benefits from massive economies of scale
	Stop guessing capacity
	Increased speed and agility
	Stop spending money running and maintaining data centers
	Go Global in few minutes
Problems Solved
	Flexibility
	Cost Effectiveness
	Scalability
	Elasticity
	High availability and Fault tolerance
	Agility ->rapidly, develop, test and launch software applications

Types of Cloud Computing
	On prem						---> Applications, data, runtime, middleware, O/S, virtualization, servers, storage, networking	
	Infrastructure As a service--> dont have to manage virtualization, servers, storage, networking	
	Platform as a service----> dont have to manage runtime, middleware, O/S, virtualization, servers, storage, networking ..Only applications and data
	Software as a service-----> Also applications and data everything is managed 	
		
AWS pricing model
			Compute-> pay for compute time
			Storage-> pay for amount of data stored
			Networking-> Pay when Data leaves the cloud
		Thus we only pay what we need
AWS history
			2002->internal
			2004 SQS first public launch and offering
			2006 relaunch with EC2, SQS
AWS regions
			All around the workd
			Names can be us-east-l, eu-west-3
			A region is a cluster of data centers
			Most AWS services are region scoped?
How do you choose an AWS region?
			Compliance --Data in france should be in france
			Latency--> close to users
			Available services--->Are the services you are looking for available in the region
			Pricing
Availability Zones
			One or more discrete data center with redundant power, networking and connectivity
			Each AWS region has many availability zones (min 3 max 6)
			Separate from each other so isolated from disasters	
			Connected to each other with ultra low latency high bandwidth networking
AWS points of presence(Edge locations)?			
		216
		For content delivery as close as possible to users

AWS console
		Global console for some services such as Route 53
		IAM is a global service encompasses all regions
		For EC2 view is different for each region in terms of the resources one sees	
AWS global infrastructure
		Information around services
AWS regional services
	Gives you services list by a region
	If you dont see a service then you may have to switch region in the console because not all services are located in the same region
	New EC2 experience toggle on top left.. switching it off would make the old UI appear
Shared Responsibility Model for Security 
	You as a customer are responsibility for security in the cloud--> security, data, network firewall conf,platform, application, identity and access management
	AWS Responsible for security of the cloud-->infra, hardware, software, internal security

---------------------Section 4------------------------------------------------------------------------------------------------
IAM
		Global Service
		Root Account shouldnt be used or shared
		Create users for people within your organization and if needed users can be grouped together
		Groups can only contain users, not other groups
		a user can belong to multiple togethers
		A user may not be part of any group but its not best practice
		Groups for permissions
		Users or Groups can be assigned JSON documents called policies
		Policies define what permissions can be assigned to users -> effect, action & resource
		Least privelege principle: Dont give a user more permission than he needs
		IAM->Create user->add user to a created group admin with Admin access policy
		Tags key value pairs to add information to assist search capabilities when searching resources.
Account Alias
		Helps you create alias and generate sign in URL for users of your account ..the users can then sign in as IAM user
		https://-*.signin.aws.amazon.com/console
		IAM user will show as IAM user in the right hand side
		Root will show as root
		Preferred to login as IAM user
IAM Policies Inheritance
IAM Policy Structure
			Version,Id,One or more Statements, a statement has Sid(Optional), Effect->allow,deny, Principal->account, role to which this policy applies to 
			Action->List of action this policy allows or denies, resources-> list of resources to which the actions are applied to
Inline policy-> policy directly for a user
You can also create custom policies


----------------------Section 5-----------------------------------------------------------------------------------------
EC2
Billing & Budget
		If you let IAM users who are admins to access billing data: From root->account->edit IAM user and role access to billing information
		IAM user/role access to billing information is activated.
		Now login as IAM user
		Home--> see bills--> charges by account, by service etc
		AWS Free TierInfo --> gives info about AWS free tier
		Set up Budget-> To control cost->Choose budget type-->zero spend budget, monthly cost budget
		
EC2 
	Elastic compute cloud ..one of the most popular of AWS offering
	Infrastructure as a service
	Rent virtual machines (EC2), store data on virtual drives (EBS), distribute load across machines (ELB), Scale services using autoscale group ASG	
EC2 sizing and configuration
	OS,Compute power and cores,RAM,storage space - network attached(EBS &EFS), network card, firewall rules security group
	Bootstrap script	
EC2 user data
	BootStrap script (configure at first launch)...bootstrap instances using EC2 User Data Script	
	Script is run only at first start
	bootstrapping launching commands when a machine starts
	EC2 user data runs with the root user.. so sudo root
	t2 micro is part of aws free tier (up to 750 hours in a month)
	Need key pairs for SSH
	.pem for above windows 10
	Allow HTTP traffice from internet because we have to configure web server
	Delete on termination EBS--> once we terminate the volume is also going to be deleted
	Advanced-> User data ..enter following bootstrap code (Install web server)
	
	#!/bin/bash
	# Use this for your user data (script from top to bottom)
	# install httpd (Linux 2 version)
	yum update -y
	yum install -y httpd
	systemctl start httpd
	systemctl enable httpd
	echo "<h1>Hello World from $(hostname -f)</h1>" > /var/www/html/index.html
	Use http://public ip
	Private Ip to connect from outside
	Stop instance---> no longer billed..instance state is kept
	however the public ip might have changed, private ip will always same

EC2 instance types
	https://aws.amazon.com/ec2/instance-types/
	A)General Purpose
		m5.2xlarge
		m instance, 5 generation, 2x large size of instance
		t2.micro general purpose ec2 instance
	B) Compute Optimized
		compute intensive tasks that need high performance processors
		media transcoding
		Dedicated Gaming servers
		High performance computing
		Scientific modeling & machine learning
		C5, c6
	C) Memory Optimized
		Process large data sets in memory(RAM)
		High performance (in memory databases for BI)
		Real time processing of unstructured data
		R6, R5
	D) Storage optimized
		Storage intensive tasks that require high sequential read, write access to large data sets on local storage
		Distributed file systems
		OLTP systems
		I4
	ec2instances.info -> Compare all instances

Security Groups







------------------------Amazon S3-------------------------------------------------
One of the main building blocks of AWS
At its core, its storage(backup, storage)
Infinitely scaling storage	
Many websites use Amazon S3 as the backbone
Many AWS services use Amazon s3 as an integration as well	

Uses
	Backup and storage
	Disaster recovery
	to host media
	to host applications 
	Static Website
	Archive
	Static website
	Nasdaq stores 7 years of data into s3 Glacier
Amazon S3
	Allows users to stores object (file) into buckets)top level directories
	Must have a globally unique name
	Buckets are created in a region
	Objects (files) have a key
	prefix+ object name
	There are no directories..keys a very very long names with /
	Object Values are contents of the body
	Max object size is 5TB
	if uploading more than 5 gb must use multi part upload
	Bucket names globally unique
Bucket policy S3 security
	User based-> IAM policies --> which API calls should be allowed for a specific user from IAM
	Resource based-> bucket wide rules allows cross account, object ACL , bucket ACL 
	Another way is to encrypt object using encryption keys
S3 Bucket Policies
	Resource: buckets and objects the policy applies on 
	Effect Allow:Deny
	Actions: Set of API to allow/deny
	Principal: The account or user to apply the policy to
	
	Anonymous user wants to access S3 bucket then use S3 bucket policy that allows public access
	IAM user wants to access S3 bucket, assign IAM permissions to user through policy, then user can access that S3 bucket
	EC2 instance wants access to S3 bucket, then IAM user permissions are not appropriate, we need to use EC2 instance role with correct IAM permissions and EC2 instance will get instance to s3 buckets
	Cross account access->use s3 bucket policy that allows cross account access
	For block public access-> by default to prevent company data leaks
	Can also be set at account level if none of your S3 buckets should ever be public
Hands on
	Make S3 as public
	Use policy generator https://awspolicygen.s3.amazonaws.com/policygen.html
	arn:aws:s3:::saurabh-******r-s3/*, get object
	principal->users
	resource is resource
	
	{
    "Version": "2012-10-17",
    "Id": "Policy1679878858678",
    "Statement": [
        {
            "Sid": "Stmt1679878757567",
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::saurabh-******r-s3/*"
        }
    ]
}
	
	
Static Website
		 S3 can host static websites and have them accessible on the internet
		 Attach S3 bucket policy that allows it to be public (cannot be private)
		 S3 properties->static website hosting
Amazon S3 Versioning
		Versioning is possible
		Enabled at bucket level
		Same key overwrite will change version
		Protect unintended delete, rollbacks
		Any file that is not versioned prior to enabling will have version null
		Suspending will not delete the previous versions
	HandsOn
		Go to Properties->enable versioning
		Show versions 
		If you delete with show versions toggle off -> delete marker will override previous file
		Delete delete marker will restore previous file

Amazon S3 replication (CRR & SRR)

		
-------------------------------Databases -------------------------------------------------------
Storing data on EBS, S3, EFS, EC2 Instance store can have its limits		
No SQL Databases -Non relational
	Modern databases --> built for a specific data model and have flexible schema for building modern applications
	More flexibility, Scalable(Horizontal scaling) , High performance and highly functional ->optimized for a data model 
	Eg, key Value, Document, graph, In memory, search databases
	Data can be in JSON format
AWS will offer use to managed databases
		Advantages of managed database
		Quick provisioning, high availability, vertical and horizontal scaling , Upgrades, patching, monitoring , autmated backup & restore
		You can use EC2 but IaaS shortcomings
		
RDS
	Relational Database service.. Use SQL as query language
	OLTP
    Create databases in cloud managed by AWS ..PostGres, MySQL, Aurora (AWS proprietary database)
	Storage backed by EBS
	But you cant SSH into the instances
Aurora
	Supports 2 kinds of database technologies PostGres and My SQL
	AWS cloud optimized 5x performance improvement over My SQL on RDS
	Grows in increments of 10GB upto 128 TB
	Proprietary(not open source)
	RDS & Aurora are 2 ways of creating relation databases in AWS
	CLoud Native version
 
HandsOn
	Database port 3306
	VPC security group (firewall)Info
	Choose one or more VPC security groups to allow access to your database. Make sure that the security group rules allow the appropriate incoming traffic.
	New VPC security group name: demo-database-rds 
	Take a snapshot so that you can rollback

Actions can be done from RDS snapshot	
	You can restore from a snapshot to a new database, create a new database out of snapshot, create a db with different settings or a bigger db, or create a copy
	Copy snapshot to a different region for disaster recovery
	Share snapshot so you can share your copy of database to another accounts so they can create/restore the database from your snapshot

RDS Deployment Options
	Read Replicas
		Create Read Replicas ->distributing reads upto 15 read replicas
		Writing Data is done to only one main DB
		Sharing load
		Main purpose scalability
	MultiAz->
		Failover In case of AZ outage..
		Failover DB takes over in case the main DB is unaccessible due to AZ outage
		Reads and writes are written to the failover DB.it is passive
		Can have only 1 AZ as a failover zone
		Main purpose availability
	MultiRegion(read replicas)
		Application and read replica exists in different zones
		Application reads data from read replica (local DB) in same AZ where the application exists
		All writes from applications across zones happen to one main Database
		Provides disaster recover strategy	
		low latency
		Cons: Replication cost associated with the network transfer data across regions
		
Amazon ElastiCache
	Managed Redis or Memcached
	Caches are in memory database with high performance, low latency
	Reduce load off databases for read intensive workloads

DynamoDB		
	Fully managed highly available with replication across 3 AZ
	NoSQL DB not a relational DB (key-value DB)
	Amazon's flagship product
	Scales to massive workloads, distributed serverless database (dont provision instance type thats why serverless)
	Scales to millions of requests per second, trillions of rows, 100's of TB of storage
	Single digit millisecond latency
	standard and frequent IA table class
	Key->(partition key+sort key)
	Value->Column attributes

DynamoDB Accelator- DAX	
	Fully managed in memory cache for Dynamo DB	
	Integrated and only used with Dynamo DB (microsecond latency)
	Secure, highly scalable and highly available	
HandsOn
	Serverless, create db without having to create instances
	Cannot normalize.. link data between tables
	So we have to make sure our relevant data is well formatted within our main Dynamo DB table	

DynamoDB- Global tables
	Make a dynamoDB table accessible with low latency in multiple regions
	Create a global table in another region and set up 2 way replication between the tables
	Active-Active replication.. writes in one region are propogated everywhere	
	Upto 10 tables in 10 regions
	Users close to a specific region can access the data from table close to their region thereby helping with low latency

Amazon Redshift 
	Based on PostGreSQL but not used for OLTP
	Its OLAP (analytics and data warehousing)
	Analyzing data and making computations
	Load data every hour not every second
	10x performance better than other data warehouses
	Columnar storage of data (instead of row based)
	Massively parallel Query execution 
	BI tools to integrate with it
	
Amazon EMR
	Elastic map reduce
	EMR helps Create hadoop cluster to analyze and process vast amounts of data
	The clusters can be made of 100's of EC2 instances that will be collaborating together to analyze your data	
	Also supports Apache Spark ,Hbase, Presto, Flink will be working on top of your hadoop cluster
	EMR takes care of provisioning and configuring these EC2 instances so they work and analyze data together from a hadoop perspective
	data processing, machine learning, web indexing, big data

Amazon Athena
	Serverless query service to perform queries against S3 objects
	Analyze data in S3 using serverless SQL
	Uses SQL to query the files
	Supports CSV, Json, ORC, Avro ,Parquet
	Can have reporting on top of athena such as using Amazon Quicksight
	BI, Analytics, Reporting, analyze and query VPC logs,ELB logs, CloudTrails trails

Amazon QuickSights
	Serverless machine learning powered BI service to create interactive dashboards
	Per session pricing
	Usecases: Business Analytics, Building Visualizations, get business insights using data
	Integrated with RDS, Aurora, Athena, Redshift, S3	
	
Amazon DocumentDB
	Aurora version of MongoDB
	MongoDB-Used to store, query and index JSON data
	Fully Managed, highly available, replication across three zones	
	Scales to workloads with millions of requests per second

Amazon Neptune	
	Fully Managed Graph Database
	Replication across 3 AZ's upto 15 replicas
	Work with Highly connected datasets
	Can store up to billions of relations and query the graph with milliseconds latency
	Great for storing knowledge graph(such as Wiki), fraud detection, recommendation engines, social networking

QLDB Overview(Quantum Ledger Database)	
	Used to review history of all changes made to your application data over time
	immutable system
	Better performance than common ledger blockchain frameworks
	There is no concept of decentralization ,it has a central authority components and is a ledger, write to only one central database, in accordance with financial regulation rules
	
Amazon Managed BlockChain
	Blockchain makes it possible to build application where multiple parties can execute transactions without the need for trusted central authority
	Amazon Managed Blockchain is a managed service to
		Join public blockchain networks
		create your own scalable private network	
	Compatible with 2 blockchains ethereum,hyperledger fabric
	Decentralized blockchain

AWS Glue
	Managed ETL service
	Use to prepare and transform data for analytics	
	Fully serverless service
Glue Data Catalog
	Catalog of datasets in AWS infrastructure
	 store structural and operational metadata for data assets
	reference (metadata) col name, col type ,etc
	can be used by Athena, Redshift OR EMR to discover data sets and build proper schemas for them
	
DMS DataBase Migration Service	
	Quick and secure db migration service that will be resilient and self healing
	Source Database remains available during migration
	Homogenous and heteregenous migrations 
--------------------Other compute Services----------------------------------------------------------------------------------------------
Docker
	Software development platform to deploy applications
	Traditonally install them on linux and then they will work
	With docker, package your apps in container..the container is very special can be run on any OS very easily..
	Apps once in the container run the same regardless of where they run(any OS)
		Any machine
		No compatibility issues
		Predictable behaviour
		Less work
		Easier to maintain and deploy
	Scales container up and down very quickly	
	Docker images are stored in docker repositories hub.docker.com
	Find base image for many systems Ubuntu,MySQL
	Amazon ECR->Private docker repository for private images
	
	
ECS
	Elastic container service-> used to launch docker containers on AWS
	You must Provision and maintain infrastructure (First create EC2 instances)
	Responsible for starting and stopping containers	
	Has integration with Application load balancer
	Whenever there is a new docker container, it determines on which EC2 instance should we run the docker container

Fargate
		Launch docker containers however do not need to provision the infrastructure(need not create EC2 instances)
		Serverless offering
		With Fargate AWS run containers automatically based on CPU/RAM for each container (we do not know exactly where)

Amazon ECR->Private docker registry (repository)	 for private docker images so it can be run by ECS or Fargate. 	

Serverless
		Developers dont have to manage servers anymore
		They just deploy code/functions 
		Initially it was pioneered as (Function as a service with AWS lambda)..just deploy your code and each function will be run independently by the lambda service
		Serverless doesnt mean there are no servers.. it means there are servers but you dont see or manage them as an end user
		Examples
		Amazon S3 could scale infinitely
		Dynamo DB ..table could autoscale
		Fargate

AWS Lambda Overview
		Conventionally when we have an EC2 instance
			Virtual server in the cloud
			Limited by RAM and CPU
			Continuosly running
			Scaling means intervention to add/remove servers
		Lambda is new way to think about it. In this case
			Virtual functions - no servers to manage
			Limited by time - short executions
			Run On Demand
			Scaling is automated
			Easy Pricing
		Event driven-> functions get invoked by AWS when an event happens/needed ..reactive type of service
		Integrated with many programming languages
		Easy monitoring through Cloud Watch
		Scale automatically as needed
		Invocation upto 15 mins
	Lambda container image
		They let you run docker images on top of lambda 
		These container images must implement the Lambda Runtime API
		Lambda does not support arbitrary docker images
		ECS/Fargate is preferred for running arbitrary docker images
	
	Serverless Thumbnail creation	
		S3 whenever image is uploaded-> AWS lambda performs thumbnail creation --> stores thumbnail back in S3--> stores meta data in Dynamo DB
	Serverless Cron Job
		CloudWatch Events eventbridge-> Aws lmabda function trigger every 1 hour... perform a task
	Pricing based on calls and duration	
	(1) time run * RAM provisioned
	(2) by number of invocations
	pay per calls ..very cheap
	1 million calls free
	20 cents after that
	Its very cheap hence its very popular	

Hands on
	Why is CPU memory on Lamnda function configurable?
	Integrated with CloudWatch logs


Amazon API gateway
	Lambda function is not exposed as an API right away.. so you need a proxy API
	We need to expose it through an API gateway..expose lambda functions as HTTP API
	Client talks to API gateway, API gateway will proxy the request to Lambda function which will execute the transformation on your data
	Fully managed serviced to create, publish, maintain, monitor and secure API's in the cloud
	Serverless, support restful API's and also websocket API's for real time streaming of data	
	Support for security, user authentication, API throttling, API keys, monitoring
	
AWS batch
	Fully managed batch processing at any scale
	Effeciently run 100,000 of computing batch jobs on AWS
	A batch job is a job with a start and an end (opposed to continuos)
	Batch will dynamically launch EC2 instances or Spot instances 
	Batch will provision the right amount of compute/memory
	You submit or schedule batch jobs and AWS batch does rest
	Batch job are defined as docker images and run on ECS
	Helpful for cost optimizations and focusing less on the infrastructure	
	
Batch vs Lambda (not very clear)
	Lambda has time limit(15mins), limited run times, limited temporary disk space and serverless	
	Batch has no time limit, any run time as long as you package in Docker image, rely on EC2 store for disk space/EBS storage 	
	Relies on actual EC2, it is not serverless (but they are managed by AWS)

Amazon Lightsail
	Standalone service(oddball)
	Virtual servers, storage, databases and networking in one place
	Low & predictable pricing, without configuring things much, get started quickly
	Simpler alternative... for people who have little cloud experience	
	Use case
			Websites(wordpress, Joomla,Lamp,Nginx)
			Dev/Test environment
	High Availability but no auto scaling, limited AWS integrations
	
--------------Deploying and managing infrastructure at scale----------------------------------------------------------------------------	
CloudFormation
	Declarative way of outlining your AWS infrastructure for any resources using a template which is YAML (or JSON?)
	Within a cloudFormation template you say
		I want a security group
		I want 2 EC2 instances using this security group
		I want an S3 bucket
		I want a load balancer (ELB) in front of these machines
		
	Then cloud formation creates those for you in right order with exact configuration you specify	
	Infrastructure as code 	
		No resources are manually created
		Changes to Infra are reviewed through code
	Cost 
		Easy to identify costs using cloudFormation template
		Ability to destroy and re-create templates on fly
			In dev you can Automate deletion of templates at 5 pm and recreated at 8 am 
	Declarative programming
		No need to figure out order and orchestration (create dynamo DB table first or EC2)
	Dont re-invent the wheel
		Leverage existing templates on the web
		Leverage documentation
	Supports almost all AWS resources	
	CloudFormation Stack Designer	
		it creates the diagram and relationship between all the resources in stack

HandsOn
	Resources:
	  MyInstance:
		Type: AWS::EC2::Instance
		Properties:
		  AvailabilityZone: us-east-1a
		  ImageId: ami-a4c7edb2
		  InstanceType: t2.micro

	Delete stack will delete all resources associated with stack..no need to delete them manually	
	Will figure out in which order to delete the resources
	Same template can be deployed to many AWS regions or AWS accounts	
	
AWS CDK
	Instead of Yaml define your cloud infra using a familiar programming language such as Javascript, Java, Python, .NET
	The code will be then compiled into a cloudFormation template(json/yaml)
	Benefits
		Deploy infrastructure and application code together as they share the same languages
		apply loop/programming constructs
	
Elastic Beanstalk
	Platform as a service. Developer centric view
	Run and manage apps
	Managed Service
	Just application code is responsibility of developer
	Full Monitoring Suite
	
AWS CodeDeploy
	Deploy appls automatically
	Works with EC2 instances 
	Works with on premise servers
	Hybrid service
	Servers must be provisioned and configured ahead of time with the code Deploy agent	
	Allows you to upgrade both EC2 instance applications and on premise server applications from a single interface
	
CodeCommit
	Store code somewhere .. before pushing application code to servers.. code repo..backed using git technology
	AWS product is CodeCommit
	Source control service that hosts Git based repositories
	Makes it easy to collaborate with others on code
	Fully managed, lived within AWS account so private, secured and integrated with AWS
	
AWS CodeBuild
	Source code built, run tests and produce packages that are ready to be deployed by Cloud Deploy
	Fully managed serverless
	Continuosly scalable, highly available
	Only pay as you go.. as your code is being built
	
AWS CodePipeline
	Orchestrate different steps to have code automatically pushed to production
	basis for CICD services
	Fully managed compatible with code commit, code build, code deploy, elastic beanstalk 
	Fast delivery, rapid updates
	
AWS CodeArtifact
	Software packages depend on each other to be built and new ones are created
	Storing and retrieving these dependencies is called artifact management
	Secure, scalable and cost effective artifact management for software development
	Gradle,Maven..talk to CodeArtifact to store and retrieve dependencies
	Developers and CodeBuild can retrieve dependencies straight from code artifact
	
AWS CodeStar
	Unified UI to easily manage software development activities in one place ..allow developers to do CICD and code
	One stop shop to start a development project, it will give a dashboard 
	And then a quick way to set up CodeCommit, CodeBuild, CodePipeline, CodeDeploy, Elastic beanStalk, EC2
	Can edit the code in the cloud using AWS Cloud9

AWS Cloud9
	Cloud IDE that is used for writing, running and debugging code
	Run in a web browser
	Cloud IDE can be used within a web browser unlike IntelliJ
	Work on your projects from your home, or anywhere with internet with no setup necessary
	Allows code collaboration in real time(pair programming)
	
HandsOn
	Very cool
	Any resource creation..always shows progress in CloudFormation

AWS Systems Manager (SSM)
	Helps you manage your EC2 and on premises systems at scale
	Get operational insights about the state of your infrastructure
	Suite of 10+ products
		Run commands across fleet of servers
		Patching your fleet of ec2 instances or on premise servers, store parameter configuration
		Configure all at once
	Works for Linux, Windows, MacOS and Raspberry PI OS	
	Install SSM agent onto systems we control
	

SSM Session manager
	Allows you to start a secure shell on your ec2 and on premises server
	No port 22 needed (better security)
	SSM managed instance core role
	Without SSH security keys and ssh access? that was disabled in security group
	Connect EC2 instance via SSM session manager
    3 ways of accessing EC2
		port 22 use ssh keys 
		ec2 instance connect without ssh keys.. but still required port 22 
		ssm ec2 instance had an iam role that allowed access
	
AWS OpsWork
		Managed Chef and puppet perform server configuration automatically or repetitive actions 
		provision Standard AWS resources
	
Cloud formation and bean stalk are free to use but you pay for resources created

-------------Leveraging the global AWS infrastructure----------------------------------------------------------------------------------------
Why Global application
	Application deployed in multiple geographies
	Decreased latency
	Disaster Recovery
	Distributed global infrastructure is harder to attack
	
Amazon Route 53
	Managed DNS
	DNS is a collection of rules and records which help clients understand how to reach a server through URL's
	A,AA.CNAME,Alias
	Simple Routing Policy
		No health checks
	Weighted Routing Policy
		This policy will allows us to distribute traffic across multiple EC2 instances (70%on first EC2, 20% on second EC2 and so on and so forth)
		This is effectively some kind of load balancing
		Can use some kind of health checks
	Latency Routing Policy
		Route 53 will choose server which is closest to user to minimize latency
		Can use health check
	Failover routing Policy
		Traffic routed to primary but in case primary fails , then clients will be redirected to failover
		Can use health check
HandsOn
	NordVPN

AWS CloudFront
	Content Delivery Network
	Caches the content of your website at different edge location, improves read performance, improves user experience, lower latency	
	We are getting DDOS protection with Shield, AWS application firewall?? how? and AWS WAF? Web application firewall, access control lists
	Origins-> CloudFront will be connect to an origin(s3 bucket or HTTP server)
		S3 bucket->for distributing files and caching them at the edge
					Enhanced Security with Origin Access Control (previously origin access identity)
					Can be used as an ingress? to upload files to S3
		Custom origin (HTTP)
			CloudFront can be in front of any custom origin backend 
			Application Load Balancer
			EC2 instance
			S3 website(first enable the bucket as a static S3 website)
			Any HTTP backend you want
	Content in S3 bucket in one location will be distributed around the world through edge locations
	Great for static content that must be available everywhere
	Files are cached for a day (TTL)
	Global edge location
	Private fast secure reliable network
	
	S3 cross region replication must be setup for each region you want replication to happen
	Files are updated in near real time
	Read only?
	Great for dynamic content that needs to be available in low latency in few regions
	
S3 Transfer acceleration
	Increase transfer speed by transferring file to an AWS edge location which will forward the data to S3 bucket in the target region
	File in USA needs to be uploaded in S3 bucket in australia
	Choose edge location closest to source file in USA..upload via public network, then use the fast private AWS network to upload the file to S3 bucket
	When you want to upload or download a file to S3 bucket that is far away from you.	
	Usecase: If you are a global application that needs to upload a file to a specific amazon bucket

AWS Global Accelerator
	Improve global application availability and performance using the AWS global network
	Optimize the route to your application
	If your website is hosted in India, and you are trying to access it from the US, the nearest edge location will receive your request
	and then traffic will flow from the edge location to and from the application(hosted server) using the private fast AWS network that edge leverages
	2 Anycasts IP are created for your application and traffic is sent through Edge locations
	Improves performance for a wide range of applications over TCP or UDP
	For global applications
	
AWS outposts
	Business that keep an on premises infrastructure alongside a cloud infrastructure are hybrid clouds
	2 ways of dealing with IT systems
		For AWS cloud using AWS console, CLI and web services
		One for their on premises infrastructure
		AWS will come and setup outpost racks that offer same infrastructure and tools to build your own applications on premises just as in the cloud 
		You are responsible for outposts racks physical security
		benefits
			Local data processing
			Low latency access to on premises systems
			Fully managed service
		Cool way to extend the cloud directly to your own premises infrastructure

AWS WaveLength
	Wavelenght zones
	Infrastructure deployments embedded within telecommunication providers datacenters (at edge of 5g networks?)
	Bring AWS services to 5G networks (Edge of 5G networks?)
	EC2,EBS, VPC
	Low latency applications through 5G networks
	Smart cities, connected vehicles, real time gaming
	Ultra low latency through 5G n/w// traffic doesnt reach AWS.. stays within Communication Service Providers Network
	But it can connect to parent AWS region and dynamo DB etc
	No additional charges
		
		
AWS Local Zones
	Places AWS compute,storage, database and other selected AWS services closer to end user to run latency sensitive applications (in addition to Az & regions)
	Extension of an AWS region?*(VPC?)
	Example AWS region N.virginia (us east 1) and has six AZ by default
	Extend AZ with help of more local zones to Boston, Chicago, Houston, Dallas, Miami 
	You can enable local zone and deploy your cloud instances there (for eg EC2) for low latency
	
Global Applications Architecture
	Single Region, Single AZ
	Single Region, Multi AZ
	Multi Region, Multi AZ (Active Passive)
		Writes happen to primary, replicated to all regions for reads and low latency
		Read latency improve but write still bad
	Multi Region, Active Active
		Reads and writes from multiple region (eg dynamo DB active active)
		More difficult to implement
--------------------------------Cloud Monitoring--------------------------------------------------------------------------------------------------------------------------
CloudWatchMetrics		
	CloudWatch provides metrics for every service in AWS
	It has a timestamp
	Can create cloudwatch dashboard of metrics
	Billing metric
	EC2 instances: CPU utilization,status checks, Network(in vs out)... every 5 mins by default
	EBS Volumes: Disk Read/Writes
	S3 buckets: BucketSizeBytes, NumberOfObjects, AllRequests
	Service metric-> how much you've been using a service API
	Custom metrics-> push your own metrics

CloudWatchAlarms
	Create Action/TriggerNotifications for any metric
	Auto Scaling increase or decrease EC2 instances count, start terminate reboot or recover an EC2 instance
	send notification into an SNS topic	
	choose the period on which to evaluate an alarm
	Create a billing arm on Cloud Watch Billing metric
	Alarm, Ok, Insufficient data are the 3 states of the alarm
	Billing Alarm is only available in US east coast?	
		
CloudWatchLogs
	CloudWatch logs can collect logs from
		Elastic BeanStalk: Collection of logs from application
		ECS: Collection from containers
		AWS Lambda: Collection from function logs
		CloudTrail: Based on filter
		CloudWatch log agents: on EC2 machines or on premise servers
		Route 53:Log DNS queries
	Collect logs from all your systems, applications and AWS services that you use, allows real time monitoring of logs
	Adjustable CloudWatch logs retention
	You need to create a cloud watch agent on your EC2 instance..they will push the log files to CloudWatch
	CloudWatch Log agent can be set on the on premises server	
		
Amazon EventBridge
	RuleType: Schedule or rule with an event pattern(through hands on)	
	Schedule: React to events within your AWS account
	Create a rule ; every hour an event generated that will run trigger script on Lambda function every hour(cron job)
	Event pattern: Event rules to react to a service doing something for eg when someone logs in as a root user, send a notification using SNS
	EC2 started, S3 upload, Code failed, schedule or cron ---> Amazon EventBridge---> Compute lamda, batch....Integration SQS, SNS, Kinesis, Orchestration CodePipeline, Maintenance SSM
	AWS services: Default event bus
	AWS Saas partners can send events to your account using partner event bus
	Also custom apps.. using custom event bus
	Schema registry: model event schema
	archive all events
	Ability to replay archived events
		
AWS CloudTrail
	Provides governance, compliance and audit for your AWS account
	Enabled by default
	Get a history of events/API calls made within your AWS account by
		Console
		SDK
		CLI
		AWS services
	Can put logs from cloudtrail into cloudwatch logs or S3 bucket (for long term retention)
	A trail can be applied to all regions or single region
	if a user deleted something.. cloudTrail
	CloudTrail Insights: Automated analysis of your cloud trail events 

AWS X-Ray
	Debugging one monolith service is easy but distributed services is hard
	No common view of entire architecture
	Visual analysis of our applications..
	Trace requests made through your distributed applications
	Advantages
		Troubleshooting performances
		Understanding dependencies in a microservices architecture
		Pinpoint service issues
		Review request behaviour
		Find errors and exceptions
		Where am I throttled
		Identify users that are impacted

Amazon CodeGuru
	An ML powered service for automated code reviews and application performance recommendations
	CodeGuru Reviewer: automated code reviews for static analysis (during development) with actionable recommendations
						Identify critical issues, security vulnerabilities, hard to find bugs
						coding best practices, resource leaks, security detection, input validation
						using machine learning and automated reasoning
						Hard learned lessons across millions of code reviews on 1000's of open source and Amazon repositories
						Supports Java and Python
						Integrates with Github, Bitbucket and AWS code commit	
	CodeGuru Profiler: visibility/recommendations about application performance during runtime
						Detect and optimize the expensive lines of code in preprod
						Identify performance and cost improvements in production
						helps identify the runtime behaviour of your application in production
						For eg: identify if your application is consuming excessive CPU on a logging routine
						Identify and remove code ineffeciencies
						Improve application performance (reduce CPU utilization)
						Decrease compute costs
						Provides heap summary (identify which objects using up memory)
						Anomaly detection in case your app behaves weirdly
	Support applications running on AWS as well as on premise
	Puts Minimum overhead on application using codeguru
		
AWS HealthDashboard-Service history
	Shows all region, all services health
	has an RSS feed you can subscribe to
	Shows historical information for each day
	Displays general status of AWS services
AWS HealthDashboard-Your account
	Provides alerts and remediation guidance when AWS is experiencing events that may Impact you
	Personalized view into the performance and the availability of AWS services underlying your AWS resource
	relevant and timely information to help you manage events in progress and provide proactive notifications to help you plan for scheduled activities
	Can aggregate data from an entire AWS organization---Organization health ..enable organizational view
Handson
	Click on bell- event log	
	
-----------------------Cloud Integration---------------------------------------------------------------------------------------------------
Amazon SQS
	Amazon Simple Queue Service
	Communication/Integration between 2 systems/services (asynchronous communication)
	To decouple between application tiers
	Oldest AWS offering
	Queue Service in AWS 
	Producers send message to the queue
	Scales from 1 message per second to 10000 per second
	Consumers polling the queue(one or multiple)
	Once the consumers read the message they are deleted
	Fully managed serverless service
	Low latency<10 ms subscribe/pub
	Web servers->EC2 instances(Web Servers) ->SQS-> EC2 instances (Video Processing)
					ASG									ASG	
	The second ASG can be scaled independently depending on how many messages are in the SQS queue.
	Default retention of message is 4 days, maximum retention is 14 days
HandsOn
	Standard & Fifo queue

Amazon Kinesis	
Real time big data streaming
	managed service to create, process and analyze real time streaming data at any scale
	Kinesis Data Stream
		low latency streaming to ingest data at scale from hundreds of thousands of sources(click streams, IoT devices, metrics & logs)
	Kinesis Data Analytics
		perform real time analytics on streams using SQL
	Kinesis Data Firehose
		load streams/output into S3, Redshift, Elastic search etc for further analysis
	Kinesis Video Streams
		Monitor real-time video streams for analytics or ML		
			
SNS overview(pub/sub)
	Simple Notification service
	Send one message to many receivers?
	Direct integration will be complicated because there will be 4 integrations
	Use SNS..the topic will send notifications to all receivers
	Notification service in AWS
	Event publisheres will send messages to one SNS topic
	As many event subscribers to listen to the SNS topic notification
	Each subscriber to topic will get all messages..different from SQS*** Consumers are sharing the messages
	No message rentention..so no storage of messages
	Each SNS topic 12.5 million subscribers
	Soft limit of 100,000 topics for each account
	SNS publish->SQS, Lambda, Emails, SMS notification, Kinesis Data Firehose, HTTP End point
										Subscribers
Handson
	saurabh-ccpdemo@mailinator.com
	Standard topic

Amazon MQ
	SNS, SQS cloud native services, proprietory protocols from AWS	
	On prem protocols --traditional MQTT,AMQP protocols-
	When migrating to cloud, instead of re-engineering the application to use SQS and SNQ we can use Amazon MQ
	Amazon MQ is a managed message broker service for 2 technologies- Rabbit MQ, Active MQ
	Doesnt scale as much SQS/SNS
	it runs on servers you can have server issue???(others do not?)
	should/*+-	1	 run in multi AZ with failover if you want it to be highly available
	Both queue and topic features
		
-----------------Machine Learning Section--------------------------------------------------------------------------------------------------	
Amazon Rekognition
	Find objects, people, text ,scenes in images and videos using ML
	Facial Analysis, face search to do user verification, people counting
	Create a database of familiar faces or compare against celebrities
	Usecases
		Custom Labeling
		Content Moderation	
		Face detection and Analysis(gender, age range, emotions)
		Face search and verification
		Pathing for sports games analysis	
		Text Detection
		Celebrity Recognition
		

Amazon Transcribe
		Automatically convert speech to text
		Uses deep learning process called automatic speech recognition (ASR) to convert speech to text accurately
		Automatically remove PII using Redaction
		Supports Automatic Language Identification for multi-lingual audio
		Usecases
			Transcribe customer service calls
			automated closed captioning and subtitling
			generate meta data for assets to create a fully searchable archive
			Identify and remove PII using redaction
			
		Automatic language identification
			If you do not know the language spoken in audio files, use this option
			To improve accuracy however you need to select a minimum of 2 languages
			
Polly
		Turn text into speech using deep learning
		Allowing you to create applications that can talk
		Neural-> Produces the most Natural and Human like speech possible
		Standard->More robot sounding -->Produces natura+93
		.	``		23ERTYU
	4
	
	-*=-0OI-=/
	l-s*-+ounding speech

Translate		
	Natural and accurate language translation
	Localize content--> such as websites and applications for international users and to easily translate large volumes of text efficiently

Amazon Lex & connect (same technology that powers Amazon Alexa)
	ASR to speech to text
	Natural language understanding to recognize the intent of text, callers
	Help build chatbots, call center bots
	
Amazon Connect
	Receive calls, create contact flows, cloud based virtual contact center
	80% cheaper than traditional contact center solutions
	Phone call->Connect->Lex(understand intent)->invoke Lambda function ->go to crm and schedule meeting... 

Amazon Comprehend
	for NLP
	Use machine learning to find insights and relationships in text
	tokenizations, POS, organizes collection of text files by topic
	Take a lot of data..text or unstructured and analyze them
	
Amazon SageMaker	
	Fully managed service for developer/data scientists to build ML models
	Whole process of labeling, building the model, training it , deploying it can be done within SageMaker
	
Amazon Forecast
	Fully managed service that uses ML to deliver highly accurate forecasts
	predict the future sales of a raincoat
	50% more accurate than looking at data itself??
	Reduce forecasting time from months to hours
	Historical Time series Data such as product features, prices, discounts, website traffic , store locations
	Upload to amazon S3->start amazon forecast service-> creates a forecasting model

Amazon Kendra
	ML powered search engine
	Fully managed document search service powered by Machine learning
	Extract answers from within a document(pdf,html,ppt,docx)
 	Kendra will internally build a knowledge index powered by ML
	Learn from user interactions/feedback to promote preferred results
	Fine Tune search results

Amazon Personalize
	Fully managed ML service to build apps with real time personalized recommendations
	to create a personalization model that generates recommendations for each customer
	Same technology used by Amazon.com
	Integrates into existing websites, applications,SMS, email ,marketing systems
	Use cases
			Retail
			Media
			Stores and Entertainment
Amazon Textract
	Extracts text, hand writing and data from scanned documents using AI & ML
	Eg Driving license
	Extract data from forms and tables, read and process any type of documents (pdf's)
	Use cases : financial services, healthcare, passports, tax forms	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
-----------------OpenAI----------------------------------------------------------------------------------------------
OpenAI
	Research and development company
	Manage models using API that you can deploy and integrate in your application
	Gather lots of data, train the model..give you access to the model using API and charge you everytime you invoke the API
GPT3
	Give it a prompt and it will complete the prompt for you, hence its called a completion model
	Natural language tasks with prompt " create a slogan for an all or organic ice cream company"
DALL-E
	Create original images or edit them "show a dog and cat chasing each other on a busy street"
Codex
	Convert natural language to code .. for eg: create a function that returns the square of a number in python	
	
Within GPT3
		davinci-> most capable model with higher quality->cost high-->request size can be high 4000.. so you can provide longer prompts and get longer respnses that are more complex
				 Create Generation and Completion. Also good at conversation, transformation

		curie->more nuanced tasks like sentiment analysis, complex classification, language translation
		babbage->simple classification, semantic search->low proce
		ada->parsing text, address correction and certain classification tasks
		
Key Concepts
		Prompts: in any NLP, prompt is What you give to the model? Response is what you get out. Prompts should be carefully created for model to react accurately
				Be very instructional in what you want and as specific as you want.
				Provide examples with good quality data and tell the model; show and tell the model how to respond
				Dont rely on factual responses.. Its only been trained on data until 2021. So it wont perfect well.
		Tokens:
				Tokens are the currency on Open AI's GPT model. Every time you ping the model it uses some tokens. The amount of token used is
				a combination of the amount of words used in prompt as well as the amount of words/text return by chat Gpt model in the response
				Its hard to know the exact tokens. 1 token is approx 4 chars , 75 words= 100 tokens
				For GPT max is 4000 token which is 3000 words
				2 cents every 1000 tokens
				Free trial usage of $18.. Total 675k words by math
				Davinci takes 4000, so it can take a much bigger prompt
		Temperature:	
				A parameter from 0-1
				Higher value means the GPT model will take more risks.. lower values means the GPT answer will be more confident in its answer when it responds
				Try 0.9 for more creative applications, and 0 for a well defined answer..
				Return the same response with temperature.. ice cream company slogan.. for different responses, make temperature up
				
Environment
		Go to personal->view API keys		