Microservices
	Architectural style where a software system is composed of multiple small automomous services that communicate over the network over well defined API's. Make applications easier to scale,faster to develop, enabling innovation and accelerating time to market for new features. 
	
	Smaller the service more you maximize the benefits and downsides of microservice architecture
	The complexity emerges from having more and more moving parts
	 The challenge is to find the right balance where services remain independent yet manageable.
	All communication between services are via network calls to enforce seperation between services and avoid the perils of tight coupling
	Microservice may be deployed on a PaaS or may have its own operating system process
	Microservices are services exposed by REST
	Small well chosen deployed units with very well thought out boundaries
	
	Defining Service Boundaries
	Evolutionary Process: Determining the right boundaries for microservices is not a one-time design decision but an evolving process that requires deep business domain knowledge.
	Business Knowledge: Properly grouping functionalities depends on understanding the business context, which ensures that each microservice encapsulates a distinct business capability.
	
	Configuration Management
	Multiple Instances and Environments: With numerous microservices running across various environments (development, testing, production), managing their configurations becomes complex.
	Centralized Management: Solutions like centralized configuration repositories (e.g., Spring Cloud Config, Consul, or etcd) are often necessary to keep settings synchronized and manageable across all services.
	
	Dynamic Scaling
	Independent Scaling: Each microservice can be scaled up or down based on its load requirements.
	Automation Required: Effective scaling requires automation through container orchestration platforms (like Kubernetes) and dynamic load balancing to adapt to changes in traffic.
	
	Visibility and Monitoring
	Centralized Logging: With many moving parts, identifying the source of bugs or performance issues demands a centralized logging system that aggregates logs from all microservices.
	Real-Time Monitoring: Automated monitoring systems (using tools like Prometheus, Grafana, or ELK Stack) are essential to track service health, pinpoint outages, and maintain overall system visibility.
	
	Fault Tolerance and Resilience
	Inter-Service Communication: Microservices interact over the network, so the failure of one service should not cascade and affect others.
	Fault Tolerance Strategies: Implement mechanisms such as circuit breakers, retries, timeouts, and fallback procedures to ensure that if one service fails, the rest of the system can continue functioning.
	
	Resilience in Practice: Building robust fault tolerance is key to maintaining system availability and preventing cascading failures, even in the event of individual service outages.
	
	
The Single Responsibility Principle (SRP) states that a module, class, or service should have only one reason to change. This means that each component should focus on a single functionality or concern, making it easier to maintain and scale.

	Breaking It Down:
	"Gather together things that change for the same reason"

	If multiple functions or components frequently change due to the same business requirement, they should be grouped together.
	Example: In an e-commerce system, the order processing logic (validating orders, applying discounts, and calculating totals) should be in the same service because changes in pricing rules or discount policies affect all these functionalities.
	
	"Separate those things that change for different reasons"
	If two functionalities are modified due to different business needs, they should be split into separate components.
	Example: User authentication (handling login, password resets) and order management (processing and tracking orders) have different reasons to change. Keeping them in the same module leads to unnecessary dependencies.
	
	
	
	Applying SRP in Microservices:
	Service boundaries should align with business domains, meaning each service should handle a well-defined part of the business.
	For example, an e-commerce platform can have separate services for:
	Inventory Service (Tracks stock levels)
	Payment Service (Handles transactions)
	Shipping Service (Manages deliveries)
	
	By applying SRP at the service level, we ensure that changes in one business area don’t unnecessarily impact others, making the system more modular, scalable, and maintainable.


	
	These services need to be able to change independently of each other and be deployed by themselves without requiring consumers to change
	Think about what needs to be shown and what needs to be exposed,If there is too much sharing, our consuming services become coupled to our internal representations. Thisdecreases our autonomy, as it requires additional coordination with consumers when making changes.
	Our service exposes an application programming interface (API), and collaborating services communicate with us via those APIs. We also need to think about what
    technology is appropriate to ensure that this itself doesn’t couple consumers. This may mean picking technology-agnostic APIs to ensure that we don’t constrain technology
    choices. 
	To do decoupling well, you’ll need to model your services right and get the APIs right
	With microservices adopt technology more quickly and understand how new adoptions may help us 
	Technological heterogeniety
		With a system composed of multiple collaborating services, we can decide to use different technologies inside each one
		This allows us to pick the right tech stack for the right job rather than to having a standardized one size fits all approach
		If one part of our system needs to improve its performance, we might decide to use a
		different technology stack that is better able to achieve the performance levels required.
		We may also decide that how we store our data needs to change for different 
		parts of our system. For example, for a social network, we might store our users’ interactions in a graph-oriented database to reflect the highly interconnected nature of a social graph, but perhaps the posts the users make could be stored in a document-oriented data store, giving rise to a heterogeneous architecture
	Quick adoption to Technology	
		With microservices, we are also able to adopt technology more quickly, and understand how new advancements may help us. One of the biggest barriers to trying out and
		adopting new technology is the risks associated with it. With a monolithic application, if I want to try a new programming language, database, or framework, any change will impact a large amount of my system. With a system consisting of multiple services, I have multiple new places in which to try out a new piece of technology. I can pick a service that is perhaps lowest risk and use the technology there, knowing that I can limit any potential negative impact. Many organizations find this ability to more quickly absorb new technologies to be a real advantage for them.
		If you can rewrite your microservice in 2 weeks you may mitigate the risks of embracing new technology
	Resilence:
		With a monolithic service, if a critical component fails, it can bring down the entire application, causing a single point of failure. However, in a distributed or microservices architecture, failures can be isolated to specific services. This allows the rest of the system to continue functioning, improving resilience.
		For example, if a payment service in an e-commerce application goes down, users might still be able to browse products and add items to their cart, rather than the entire site becoming unavailable. Techniques like circuit breakers, retries, fallback mechanisms, and redundancy help ensure that failures do not cascade across the system.
	Scaling on demand for those pieces who need items
	In a monolithic architecture, scaling requires replicating the entire application, even if only a small part of it experiences high demand. This leads to inefficient resource utilization.In a microservices architecture, only the services that need additional resources can be scaled independently. For example, in an e-commerce platform, the checkout service may experience high traffic during a sale, while the user profile service remains stable. With horizontal scaling, only the checkout service can be scaled up dynamically, optimizing infrastructure costs and performance.Technologies like Kubernetes, auto-scaling groups, and cloud elasticity enable efficient on-demand scaling based on traffic and load patterns.

	
Spring Microservices (Spring boot version 3.0.6)
	
Web service
	Service delivered over the web
	Interoperability
	Without web service we need to use Jar (to provide business logic to another application)
	Software system designed to support interoperable machine to machine interaction over a network
		Designed for application to application interaction(machine to machine)
		Should be platform independent(interoperable).. Other applications installed using Java, Dotnet or PHP
		Should allow communication over a network
	Popular formats for request and response
		XML(Extensible markup language)
		Json	
	Every web service offers a service definition that the applications who are going to use web service are provided with. Service definition is the contract 
	(Service provide provides WSDL to Service consumer)
		a) request and response format (JSON/XML)
		b) Structure of the request and Response
		c) endpoint of the service
		
	Transport defines how a service is called. It can be exposed over rt
			- HTTP and MQ (service exposed over internet- HTTP or over a queue-MQ)
			- Just how you type the URL in browser, same way an application will call the web service
			- Service requestor will place the message on queue, Service provider will be listening on the queue, do the processing, create the response and put it back
			  on the queue
			  
	
SOAP web services (Simple Object Access Protocol) 
	Defines a specific way of building services
	XML is used as the request and response exchange format
	SOAP defines a specific request and response structure	
	SOAP envelope (header(optional)->authentication, authorisation) +body
	You have to adhere to the above format SOAP XML structure
	
SOAP does not pose any restrictions on your transport	
	Use HTTP or MQ
	Service definition is done using WSDL
	
REST( Representational state transfer)- Architectural approach
	HTTP is a protocol which is used to browse and access the web
	Rest is Based on HTTP, Make best use of HTTP to develop web services as well
	Most important abstraction in REST is called Resource, a resource is anything that you want to expose to the outside world through your application
	A resource is a URI	user/saurabh/todos/1 -> a resource can have different representations XML,HTTP,JSON
		create a user do a POST /users
		delete user 1 do a delete /user/1
		get all users do a get /users
		Get one user do a get/user/one	
	When you type URL in browser, sends a get request to the webserver, server sends the HTTP response containing the HTML which is rendered on your browser
	HTTP defines the header and the body of the request
	HTTP also defines something called request methods.
	You can indicate what action you are doing by using the HTTP request methods.
	Get, I'm trying to get the details of something, Post, I'm trying to create something, Put, I'm trying to update something.
	A HTTP response will also include a HTTP status code
	Rest has no restriction on data format(Json is popular)...transport is always over HTTP.. there is no standard service definition or service definition language
	WADL/Swagger.. (one of the formats to specify)
	RESTful services are easier to implement than SOAP
	
Soap VS REST
	Not an apple to apple comparison, SOAP is restrictions, REST is architectural approach
		

Spring boot vs Spring MVC vs Spring
	Conventional Spring
		1)Dependency Management - for rest API you would need spring framework, spring MVC framework, JSON binding framework.. For spring- Spring test, Mockito, JUnit
			Create a pom.xml with all dependencies and versions
		2) web.xml (Web app configuration)
			Configure Dispatcher Servlet for Spring MVC
		3)Component scan and view resolver , define a data source  manage spring beans..context.xml
		4) NFR's logging, error handling, monitoring
	Repeat this for every project
	Spring Boot makes it easy
		
Spring Boot--
	Help you build production ready apps quickly-- Goal of Spring boot
	Spring Initializr Create RestAPI
	Spring initializr: start.spring.io
	Snapshots are the developing versions
	Add dependency, group, artifact name, download zip, import intellij and start	
	@RestController for controller class
	@RequestMapping("api/order")
    @PostMapping
		  private final OrderService orderService;
		  public String placeOrder(@RequestBody OrderRequest orderRequest){
				return orderService.placeOrder (orderRequest);
		 }
	http://localhost:8080/courses
	One class has @SpringBootApplication annotation..that class has to be outside//other classes can be in subpackages
	RestfulWebServiceApplication
	//SpringBootApplication
	SpringApplication.run(RestfulWebServiceApplication.class, args);
	Instead of @RequestMapping(method= RequestMethod.GET) you can use @GetMapping(path="/courses")
	Maven use Bundled Maven 3


Spring Boot- Starter projects
	Group dependencies and make it easy to build applications
	Starters->Convenient dependency descriptors for different features
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
		
		Spring Boot Starter Data JPA
		Spring Boot Starter JDBC
		Spring Boot Starter Security
		For Spring boot Starter web
			Dispatcher servlet
			Embedded Servlet container
			Default error pages
			Bean Json convertor( jackson)
	Spring boot provides a variety of starter projects depending on what kind of application you are designing	
	
Spring Boot- Auto configuration	
	Automated configuration for your app
		Decided based on 
			1) What frameworks are in your class path
			2) What is the existing configuration (annotations) ?
		Spring boot autoconfigure jar does the magic
		Go to application.properties and put 	
		See Positive matches and negative matches 
		
		Eliminate Configuration to setup Spring, Spring MVC and other frameworks	
			
Spring Boot Dev Tools
	Setup for IntelliJ
	https://stackoverflow.com/questions/33869606/intellij-15-springboot-devtools-livereload-not-working			
	Increased developer productivity
	Why do you need to restart manually for every code change?
		<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-devtools</artifactId>
		</dependency>	
	
	If you are making changes to pom.xml, then you have to restart the application manually	
	
Spring Boot-Profiles
	Enables you to specify environment specific configuration
	Create a specific profile for each different environment(configuration)
	application.properties..create seperate file for each environment application-dev.properties
	Go to application.properties and set active profiles
		spring.profiles.active=dev
	The dev profile will now supersede the property in the default profile for the application
	
Spring Boot- Configuration Profiles
	See demo 
	Centralized class for the application related configuration
	A combination of configuration properties and profiles in spring boot is powerful, externalize all configuration needed for your application

Spring Boot embedded server
	Old ways of deploy 1) Install Java 2) Install tomcat 3)Deploy War(Web archive)
	Embedded server is simpler alternative, the server(tomcat) is already part of your jar file
	Install java and run your jar file
	C:\Users\saura\repo\learn-spring-boot\target\learn-spring-boot-0.0.1-SNAPSHOT.jar
	Just run the jar (tomcat is part of our jar)
	It simplifies the deployment process
	Default is starter-tomcat(jetty,undertow is also supported)
	
Spring Boot Actuator
	Monitor and manage your application in production
	Provides a number of endpoints
		beans-complete list of spring beans in your app
		health- Application health information
		metrics- Application metrics
		mappings - Details around request mappings
		<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>		
	In application.properties, management.endpoints.web.exposure.include=* or you can specify health,metrics
	http.server.requests
	http://localhost:8080/actuator/metrics/http.server.requests
	Provides a lot of information about the application and the environment in which your application is running


Spring boot vs spring mvs vs Spring

		Spring framework is about dependency injection, Identifying the dependencies @Component,@Service, @Autowired, Component scan-- identify all components
			Spring modules and spring projects extend the spring eco system ..provide good integration with other frameworks (Hibernate/JPA, Junit, Mockito	)
		Spring MVC is a spring module ->Only focus on Simplify building wep apps and rest api
			@Controller, @RequestMapping, @RestController
			@RestController returns @ResponseBody (return data instead of jsp pages)
		SpringBoot (Wrapper that makes it easy to use Spring MVC and Spring)
			To build production ready apps quickly
				Starter projects easy to build wide variety of applications
				Eliminate Configuration to setup Spring, Spring MVC and other frameworks. 
				Default conf based on what is in your classpath
				Enable non functional requirements
					Actuator-> enables advanced monitoring of application
					Embedded Server-> No need for seperate application servers
					Logging and error handling
					Profiles and Configuration properties
					
Section 3 -Advanced rest services
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-jpa</artifactId>
		</dependency>

		<dependency>
			<groupId>com.h2database</groupId>
			<artifactId>h2</artifactId>
			<scope>runtime</scope>
		</dependency>				
		
	All requests are handled by dispatcher servlet in Spring MVC
	Mapped to the root URL
	All respects irrespective of URL first come her
	Dispatches to the right controller
	Spring AutoConfiguration configures dispatcher servlet	
	How the return object is converted to Json?
		@ResponseBody+JacksonHttpMessageConverters
		@RestController has @response body and is saying return the bean as is and there will be conversion happening
		Default conversion is using JacksonHttpMessageConvertersConfiguration auto configured by SpringAutoConfiguration
	Configuring error mapping-> If you try to access a resource that does not exist (ErrorMVCAutoConfiguration)
	How are all jars available? Because of starter projects..they come in your classpath and then SpringBeanAutoConfiguration does rest of the magic
		
		
		
		
		
		
Microservices
	Its an architectural style to develop single application as a suite of small services, each running its own process
	Small autonomous services that work together
	Microservices are services exposed by REST
	Small well chosen deployed units with very well thought out boundaries
	Which are cloud enabled	Meaning -There can multiple instances for each of these microservices..using a container orchestration you can bring them up or down
	

	
SpringCloud
	
	SpringCloudConfigurationServer(Configuration management)
		Provides an approach where you can store all configuration of all different env of all different microservices in a centralized location (gi repository)
		SpringCloudConfigServer exposes that configuration to all microservices, keep all configuration in one place, makes it easy to manage
	Naming Server(Eureka)
	Service Registration and Discovery->	All instances of microservices will be registered against Eureka (naming Server )
		Currency calculation service should ask the naming server, give me all the instances who are running the currency exchange service
			and the naming server will provide that informations
	Ribbon(Dynamic scale up and scale down)
		Dynamically adjust as per load (distribute the load as per instances)
		Load is evenly distributed for the existing instances it gets from the naming server		
	Feign
		Write simple restful clients
	Zipkin Distributed Tracing (visibility and monitoring)
		We would use Spring Cloud Sleuth to assign a ID to a request across multiple components and we would use Zipkin Distributed Tracing
		to trace a request across multiple components.
	API gateways (Netflix Zuul API gateway)
		Logging, Security, Analytics and things like that (for all microservices)
	Fault Tolerance (Hystrix)	
		if a service is down, Hystrix helps to configure a default response
		
Advantages
	It allows you to adapt new technology and processes very easily
		Each microservices can be built in different technologies
		In Monolith applications we would not have that flexibility
		Microservice 1 may be java, microservice 2 may be NodeJs
	Dynamic Scaling
		If your microservices are cloud enabled they can scale dynamically and you can procure hardware and release it dynamically as well
		Scale them up and down as per your load
	Faster release cycles	
		Because you are developing smaller components easier to release microservices as compared to monolith applications
		Faster release cycles..bring new features faster to market

Standardizing Ports & URL
	Set up at least 7 projects
		Limits service 8080,8081
		Spring cloud config server 8888
		Currency exchange service 8000,8001,8002
		Netflix Eureka Naming Server 8761
		Netfliz Zuul API gateway server 8765
		Zipkin Distributing Tracing Server 9411
		https://github.com/in28minutes/spring-microservices/tree/master/03.microservices
		All URL's that are used in this course
		
V2
	SpringCloudLoadBalancer(instead of ribbon)
	SpringCloudGateway instead of Zuul
	Resilience4j instead of Hystrix

# Architecture
Limits microservice  Microservice X   Microservice Y
		\					/			/
		Spring Cloud Config Server
				\	
				Git Repo

	
#Create a LimitsMicroService		
	Config client -> Client that connects to spring cloud config server
	<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-config</artifactId>
	</dependency>
	Configure how spring cloud starter config needs to connect to spring cloud server..
	In application.properties
	spring.config.import=configserver:http://localhost:8888
	spring.config.import=optional:configserver:http://localhost:8888
	If you want to make the connection to config server mandatory, you can remove the optional
	limits-service.minimum=2
	limits-service.maximum=999
	
https://github.com/in28minutes/spring-microservices-v3/blob/main/03.microservices/01-step-by-step-changes/readme.md#spring-cloud-config-server---steps-01-to-08
	Step 04 - Setting up Spring Cloud Config Server


	
	
#Create a Git repository	
	Step 05 - Installing Git and Creating Local Git Repository
	/git-spring-boot-localconfig-repo
git-localconfig-repo/limits-service.properties New
	limits-service.minimum=4
	limits-service.maximum=996
	


#Create a config server	(Spring cloud config server connected to git repository)
On Spring Initializr, choose:
	Group Id: com.in28minutes.microservices
	Artifact Id: spring-cloud-config-server
	Dependencies
	DevTools
	Config Server
	
	<dependency>
		<groupId>org.springframework.cloud</groupId>
		<artifactId>spring-cloud-config-server</artifactId>
	</dependency>	
	
	@EnableConfigServer
	Also in application.properties
	spring.application.name=spring-cloud-config-server
	server.port=8888	
	spring.cloud.config.server.git.uri=file:///C:/Users/saura/repo/git-spring-boot-localconfig-repo
	spring.cloud.config.server.git.default-label=main (otherwise it looks in master)

Run the URL
	http://localhost:8888/limits-service/default
	
#Connect limits microservice to Spring Cloud Config Server
	spring.config.import=optional:configserver:http://localhost:8888	
	spring.application.name=limits-service (from git repo)
	http://localhost:8080/limits will give values from git repo
	When limits service start it executes the URL on cloud config server  http://localhost:8088/limits-service/default 	and get the config back

	Starting LearnSpringBootApplication using Java 17.0.1 with PID 46580 (C:\Users\saura\repo\learn-spring-boot\target\classes started by saura in C:\Users\saura\repo\learn-spring-boot)
	The following 1 profile is active: "prod"
	Fetching config from server at : http://localhost:8888

	http://localhost:8888/limits-service/qa
	http://localhost:8888/limits-service/default

	{"name":"limits-service","profiles":["qa"],"label":null,"version":"6dc2bf5235c3838010ef66a1d7028e6ab0f2618b","state":null,"propertySources":[{"name":"file:///C:/Users/saura/repo/git-spring-boot-localconfig-repo/limits-service-qa.properties","source":{"limits-service.minimum":"8","limits-service.maximum":"992"}},{"name":"file:///C:/Users/saura/repo/git-spring-boot-localconfig-repo/limits-service.properties","source":{"limits-service.minimum":"4","limits-service.maximum":"996"}}]}

	Priority with environment and second value is default

	Use this spring.profiles.active=prod
	OR
	spring.cloud.config.profile=dev
	spring.cloud.config.name?

	For another microservice.. create properties file such as microservice-x-dev.properties and so on and so forth
	So all configuration related to your application is centralized at one place..is centralized
	By seperating out your configuration from your application, you are making operations easier.. 
	Control All configurations for all microservices in all environments in a single location (git repository)		

#Debugging guide
	https://github.com/in28minutes/spring-microservices-v3/blob/main/03.microservices/01-step-by-step-changes/readme.md#spring-cloud-config-server---steps-01-to-08
	
#CurrencyExchangeServiceApplication
	spring.application.name=currency-exchange
	server.port=8000
	spring.config.import=optional:configserver:
	http://localhost:8000/currency-exchange/from/USD/to/INR
	
#Having 2 instances of the same application 
	Copy run configuration, provide VM arguments
	-Dserver.port=8001
	Whatever you provide in VM properties will override whatever is configured in application.properties
	Will launch up a new instance
	http://localhost:8001/currency-exchange/from/USD/to/INR
	You can identify which instance is being called
		
#JPA
	<dependency>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-data-jpa</artifactId>
	</dependency>	

	<dependency>
		<groupId>com.h2database</groupId>
		<artifactId>h2</artifactId>
	</dependency>
	h2 in memory database
	
	in application.properties
		spring.jpa.show-sql=true   				 (to see all SQL statements that are generated)
		spring.datasource.url=jdbc:h2:mem:testdb (otherwise you get a random database url)
		spring.h2.console.enabled=true			 (see details present in the database)
		
	When you run you see h2 console
		http://localhost:8000/h2-console/
		
	#Spring Data JPA	
		In your bean add @Entity and @Id for your primary key...h2 will automatically create tables
		If you want to have different column names than the bean use @Column(name="currency_from")	
		tables and columns are automatically created with the _ wherever there is space
		@Table if you want a different table name
		@Id,@SequenceGenerator if you want to generate sequences
		@Transient for columns you do not want to be a part of database
		Fields marked with @Transient are ignored and not mapped to any database column (in RDBMS)		
	#JPARepository
	#How to connect Service to in memory database
		public interface StudentRepository extends JpaRepository<Student,Long> {
		Student findById(int id);
		Student findByName(String name);
		}
		 //jpql
		//@Query("SELECT s from Student s where s.email=?1")
		 Student findByEmail(String email);
		 Question#: When would we need JPQL?
	#LoadData
		Create data.sql file parallel to application.properties with the insert queries
			INSERT INTO STUDENT (ID,NAME,EMAIL,DATE_OF_BIRTH,AGE) values (2,'Shyam','shyam@infy.com','1990-12-22',33)
		It gets loaded automatically before the tables are created..to prevent this use defer property in application.properties
		spring.jpa.defer-datasource-initialization=true
	#Another way	
	@Configuration
	public class StudentConfig {
		@Bean
		CommandLineRunner commandLineRunner(StudentRepository studentRepository){
			return args -> {
				Student alex=new Student(1L,"Alex","alex@gmail.com", LocalDate.of(2001, Month.JULY,23));
				Student ronya=new Student(3L,"Ronya","ronya@gmail.com",LocalDate.of(1995, Month.JULY,02));
				studentRepository.saveAll(List.of(alex,ronya));
			};

		}
		#to avoid multiple loads everytime you run
			spring.jpa.hibernate.ddl-auto=create-drop
		# 	spring.jpa.hibernate.ddl-auto=update (whenever there is change in entities it will be reflected in the database)
		#	spring.jpa.show-sql=true (always show the sql)
		In production use none	
			spring.jpa.hibernate.ddl-auto=none
	#How the controller will call the data
		@GetMapping("/api/v1/student/{id}") (connects to service..business logic layer)
		public Student getStudent(@PathVariable int id){
        return studentService.getStudent(id);
    }
	Inside service (connects to data access layer)
		@GetMapping("/api/v1/student/{id}")
    public Student getStudent(@PathVariable int id){
        return studentService.getStudent(id);
    }
		
 #Post is used when you want to add new resources
	Controller:
	  @PostMapping("/api/v1/register")
		public void registerNewStudent(@RequestBody Student student){
        studentService.addNewStudent(student);
		}
	Service
		public void addNewStudent(Student student) {
        Optional<Student> studentOptional=studentRepository.findByEmail(student.getEmail());
        if(studentOptional.isPresent())
            throw new IllegalStateException("email taken");
        studentRepository.save(student);
        System.out.println(student);
    }
POST:http://localhost:8080/api/v1/register			
		{
		"id": 5,
		"name": "Prakash",
		"email": "prakash@gmail.com",
		"dateOfBirth": "2011-07-23"
		}
First time succeeds
Second time
{
    "timestamp": "2023-06-29T14:47:34.916+00:00",
    "status": 500,
    "error": "Internal Server Error",
    "message": "email taken",
    "path": "/api/v1/register"
}		

For message to be displayed use property: server.error.include-message=always in application.properties

Delete: http://localhost:8080/api/v1/delete/5
Controller
@DeleteMapping("/api/v1/delete/{id}")
    public void deleteStudent(@PathVariable Long id){
        studentService.deleteStudent(id);
    }
Service
 public void deleteStudent(Long id) {
        boolean exists=studentRepository.existsById(id);
        if(!exists)
            throw new IllegalStateException("Student does not exist");
        studentRepository.deleteById(id);
    }
	
PUT
Update name/email
    @PutMapping("/api/v1/update/{id}")

@Transactional means you dont have to implement any jpql query		
public void updateStudent(@PathVariable Long id,
                          @RequestParam(required = false) String name,
                          @RequestParam (required=false) String email){
        studentService.updateStudent(id,name,email);
    }

#mvn clean then install will create demo snapshot jar
java -jar (name of jar) --server.port=8081
To run into another port



Youtube video		
@GetMapping for method
@RequestMapping for controller
create a final instance of service with constructor
@Autowire it

@Service in the service layer

Spring-----------------
	Inversion of control --> give control to framework itself, no need to create objects yourself.. Spring allows dependency injection
	Constructor-based Dependency Injection
	Setter-based Dependency Injection
	Field or Property-based Dependency Injectio
	 (define spring.xml and load it in main method using ClassPathXMLApplicationContext)
		XML based injection
			Constructor based injection (define constructor arg in xml)
			Getter Setter based injection(property,ref for object, value for value in xml)
				Use context.getBean(Doctor.class or "id")
		Annotation based injection	
			Give context component scan base package in context.xml
			Use @Component for classes that need to be injected (its a stereotype Component)
			@ComponentScan will scan all components in your application and all those components will be added to Spring Container 
			when spring boot starts
		Java Configuration Way
			Application context= new AnnotationConfigApplicationContext(BeanConfig.class)
			BeanConfig class have @Configuration, @ComponentScan(basePackage="demo"))
			OR
			@Bean define your bean..and return
		5 different types of scope	
			Use @Scope(scopeName="prototype")
			Singleton(Default)
				One object is created in entire application
					No matter how many times you get object from context.get(Doctor.class) you will get the same object
			,Prototype
				New object on request from each container
			,Request,
				Create a new object for every request..used in web container
			Session,
			Global Session
			Paused at 47:00
	Aspect Oriented Programming--> Logging user data, authentication and authorization.. All of this is an aspect
			remove Cross cutting concerns and seperate it out from main business logic and Run it seperately
			invoke those particular methods for every request
			aspectjrt			
			spring context
			aspectjweaver	
			@Aspect
			@Component
			public class LoggingAspect{
				@Before("execution(* demo.ShoppingCart.checkout())")
				public void logger(){
					System.out.println("loggers")
				}
			}
			
			Before the checkout method is called ..the logger will be called
			@Before, @After, pointcuts
			@Before("execution(* *.*.checkout(..))")
				All checkout methods with any number of arguments
			
	Spring provides data libraries/projects for every type of data source
#SpringBoot
	Build production ready apps quickly
	Extension of spring framework
	Spring bootprovides starter templates that groups all dependencies 
	Spring boot does autoconfiguration 
	Embedded Server
--------------------------------------Complete Spring boot app-----------------------------------------
Spring boot 3.1 Java 17 Spring framework 6		
#SpringCloud 
	Spring cloud is a project under the spring project ecosystem
	Help to build reliable and robust microservices(develop microservices)
	Spring Cloud provides tools for developers to quickly build some of the common patterns(design patterns) in distributed systems
	(eg configuration management, service discovery, circuit breaker, intelligent routing) 

#SpringWeb
	Build web including RESTful services/applications using spring MVC..Use apache tomcat as the default embedded container 
#Lombok
	To remove boilerplate code
	
#SpringDataMongoDB
	
#Api gateway
		Acts as a gatekeeper/entry point to send out requests to different services from users
		dont want to give the hostname/ip address services of microservice

#Logical architecture of each microservice		
Http request from clients->Controller->Service(Business logic...sometimes talk to MQ)->Repository(DataAcessLayer)->Database		

#application.properties
spring.data.mongodb.uri=mongodb://localhost:27017/product-service

http://localhost:8080/api/product
{
    "name": "Iphone 13",
	"description": "prakash@gmail.com",
	"price": 1200
}


Controller->Service->Repository
It is a good practice to sepeare dto from model..expose only what is needed
DTO objects are different and model is different
	For Repository
	Student findById(int id);
		Student findByName(String name);
		//jpql
		//@Query("SELECT s from Student s where s.email=?1")
		Optional<Student> findByEmail(String email);
	For Controller
		@PostMapping
		@ResponseStatus(HttpStatus.CREATED)
		@RequiredArgsConstructor instead of @Autowired?
		private final ProductService productService;
	For Service	
		@Service inject repository@Autowired
		
		 Product product=Product.builder()
                .name(productRequest.getName())
                .description(productRequest.getDescription())
                .price(productRequest.getPrice())
                .build();

        productRepository.save(product);
		//log4jfeature{}
		@Slf4j
        log.info("Product {} is saved",product.getId());
	For model
		@Document annotation for mongo db
		@Lombok annotation for getter setter and constructors
			@AllArgsConstructor
			@NoArgsConstructor
			@Builder
			@Data
				Shortcut for @ToString , @EqualsAndHashCode , @Getter / @Setter and @RequiredArgsConstructor
		@Entity
		@Table(name='') if you want to rename
		@Id
		@GeneratedValue(strategy = GenerationType.IDENTITY)
			private Long id;
		@OneToMany(cascade = CascadeType.ALL)
		@Column(length=60)
	For Repository
		public interface StudentRepository extends JpaRepository<Student,Long> {}
		
The JPA specification supports 4 different primary key generation strategies which generate the primary key values programmatically or use database features,
 like auto-incremented columns or sequences. The only thing you have to do is to add the @GeneratedValue annotation to your primary key attribute and choose a generation strategy.
		1.1 GenerationType.AUTO
			The GenerationType.AUTO is the default generation type and lets the persistence provider(could be hibernate) choose the generation strategy.
			If you use Hibernate as your persistence provider, it selects a generation strategy based on the database specific dialect. For most popular databases, it selects GenerationType.SEQUENCE 
		1.2 GenerationType.IDENTITY
			The GenerationType.IDENTITY is the easiest to use.It relies on an auto-incremented database column and lets the database generate a new value with each insert operation.(but not the best one from a performance point of view.cannot do batch operations)
		1.3 GenerationType.SEQUENCE
			The GenerationType.SEQUENCE is  preferred way to generate primary key values and uses a database sequence to generate unique values.
			If you don’t provide any additional information, Hibernate will request the next value from its default sequence. You can change that by referencing the name of a @SequenceGenerator in the generator attribute of the @GeneratedValue annotation. The @SequenceGenerator annotation lets you define the name of the generator, the name, and schema of the database sequence and the allocation size of the sequence.
		1.4 GenerationType.TABLE
			It simulates a sequence by storing and updating its current value in a database table which requires the use of pessimistic locks which put all transactions into a sequential order
			
CascadeType.ALL propagates all operations — including Hibernate-specific ones — from a parent to a child entity.
			
201Created response
Integration Tests
#tests products service -- 
#testcontainers..use docker container instances of
#IntegrationTests
#mongodbcontainer
https://java.testcontainers.org/
Define versions for all test containers.. so individual dependency doesnt need mention of containers
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>testcontainers-bom</artifactId>
            <version>1.18.3</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement> 

Now
<dependency>
			<groupId>org.testcontainers</groupId>
			<artifactId>mongodb</artifactId>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.testcontainers</groupId>
			<artifactId>junit-jupiter</artifactId>
			<scope>test</scope>
		</dependency>
		
23:47 43:		
@SpringBootTest
@Testcontainers
class ProductServiceApplicationTests {
	@Container
	static MongoDBContainer mongoDBContainer= new MongoDBContainer("mongo:4.4.2");
//from the container.. adds replica
	static void setProperties(DynamicPropertyRegistry dynamicPropertyRegistry){
		dynamicPropertyRegistry.add("spring.data.mongodb.uri",mongoDBContainer::getReplicaSetUrl);
	}
		@Test
		void contextLoads() {
	}

}	
//    @OneToMany(cascade = CascadeType.ALL)
For what?
git remote add origin https://github.com/saurabhdcagrawal/shopping-app-spring-boot.git	

@Transactional
	Why? automatically create and commit the transactions
	@Transactional is a Spring annotation that can be applied to methods or classes to indicate that the annotated code should be executed within a transaction. When Spring encounters the @Transactional annotation, it automatically creates a transaction around the annotated code and manages the transaction lifecycle.
	the default isolation level is (usually READ_COMMITTED) and the default propagation behavior (REQUIRED)
	It is a powerful tool for simplifying transaction management in Spring applications. By using @Transactional, you can avoid writing boilerplate code to manage transactions manually, and you can focus on writing business logic. However, it’s important to use @Transactional correctly and follow best practices to avoid potential pitfalls.
	Transactions ensure that multiple database operations are executed atomically, which helps to maintain data consistency and integrity.
	Use @Transactional at the appropriate level: You should apply @Transactional to the appropriate level of granularity. 
	@Transactional should not be used on public methods of a @Repository.
Difference between request param and path variable
	@GetMapping("/foos/{id}")
	@ResponseBody
	public String getFooById(@PathVariable String id) {
		return "ID: " + id;
	}
	http://localhost:8080/spring-mvc-basics/foos/abc
	
	@GetMapping("/foos")
	@ResponseBody
	public String getFooByIdUsingQueryParam(@RequestParam String id) {
		return "ID: " + id;
	}
	http://localhost:8080/spring-mvc-basics/foos?id=abc
	Because @PathVariable is extracting values from the URI path, it’s not encoded. On the other hand, @RequestParam is encoded.
	
	For storing data in table at start..in InventoryServiceApplication
	@Bean
	CommandLineRunner commandLineRunner(InventoryRepository inventoryRepository){
		return args -> {
			Inventory inventory= new Inventory();
			inventory.setSkuCode("iphone_13");
			inventory.setQuantity(100);
			Inventory inventory1= new Inventory();
			inventory1.setSkuCode("iphone_13_red");
			inventory1.setQuantity(0);
			inventoryRepository.save(inventory);
			inventoryRepository.save(inventory1);
		};

	}
#Project restructure New maven module.. to connect all the modules 
		//Dependencies add individual pom
		//Dependencies main pom..add dependency management
		//add parent as spring boot starter
	<parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.0.6</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>

		microservices parent pom
		<modules>
        <module>product-service</module>
        <module>order-service</module>
        <module>inventory-service</module>
        <module>discovery-server</module>
        <module>api-gateway</module>
        <module>notification-service</module>
    </modules>
	<dependencies>
        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>testcontainers-bom</artifactId>
            <version>1.18.3</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-dependencies</artifactId>
            <version>${spring-cloud.version}</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
#Synchronous communication
#WebClient
After you build your docker images in local push to docker hub
Image is downloaded from hub.docker.com (Docker registry)


# spring.jpa.hibernate.ddl-auto=create-drop
	Prevent duplicates when loading

# Inter Process Communication (Rest template or web client, spring boot is recommending to use web client)
	#RestTemplate
		import org.springframework.web.reactive.function.client.WebClient;
		<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-starter-webflux</artifactId>
			</dependency>
	
	#create config.WebClientConfig in order-service module
	create a bean of type webclient
	@Configuration
		public class WebClientConfig {
			@Bean
			@LoadBalanced
			public WebClient.Builder webClientBuilder(){
				return WebClient.builder();
			}
		}
		
	#Inside order service class		
		private final WebClient.Builder webClientBuilder;
		//check if product exists in inventory
        Boolean result=webClient.get().uri("http://localhost:8082/api/inventory").retrieve().bodyToMono(Boolean.class).block();
        if(result)
            orderRepository.save(order);
        else
            throw new IllegalArgumentException("Product is not in stock, please try again later");

	block will make a synchronous request
	    @GetMapping
		#@RequestParameter instead of path variable
		    public List<InventoryResponse> isInStock(@RequestParam List<String> skuCode){
		From
		@GetMapping("/{sku-code}")
		@ResponseStatus(HttpStatus.OK)
		public boolean isInStock(@PathVariable String skuCode)
	#After Changes(Order Service) (Note you need to duplicate inventoryResponse inside Order Service)
		order.setOrderLineItemsList(orderRequest.getOrderLineItemsDtoList().stream().map(this::mapToModel).collect(Collectors.toList()));
        List<String> skuCodes=order.getOrderLineItemsList().stream().map(OrderLineItems::getSkuCode).collect(Collectors.toList());
        //check if product exists in inventory
        InventoryResponse[] inventoryResponses=webClient.get().uri("http://localhost:8082/api/inventory",
                uriBuilder -> uriBuilder.queryParam("skuCode",skuCodes).build())
                .retrieve().bodyToMono(InventoryResponse[].class)
                .block();
        boolean allProductsInStock=Arrays.stream(inventoryResponses).allMatch(InventoryResponse::isInStock);
        if(allProductsInStock)	
            orderRepository.save(order);
    #order
	{
	   "orderLineItemsDtoList":[
		   {
			   "skuCode":"iphone_13",
			   "price":1200,
			   "quantity":1
		   },
           {
			   "skuCode":"iphone_13_red",
			   "price":1200,
			   "quantity":1
		   }
	   ] 
	}	
#Service Discovery Pattern (for inter services configuration)
	In cloud enviroment, we cannot have a static ip address, everything will be dynamic, we will have dynamic ip adress and different ports
	Also there can be multiple instances of inventory service microservice..
	How our order service which understance which instance of inventory service to call?	
	Creating a server which will store all the information of services (service name and ip)
	Microservices at the time of starting will register themselves to discovery server by making a request	
	Discovery service will add this information to its local copy also called as its service registry
	When order service calls inventory service, the order service will make a call to discovery..
		Discovery server will give ip address of inventory service.. 
		It will also give a local copy to the order microservice 	.(in case discovery service is not available)
	Avoid hardcording url of the inventory service by making use of the discovery server
	#Netflix Eureka		
		Comes from different group id
		For the client pom (not from org.springframework.boot)
		<dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
        </dependency>
	@SpringBootApplication
	@EnableEurekaServer
	public class DiscoveryServerApplication {
		public static void main(String[] args) {
			SpringApplication.run(DiscoveryServerApplication.class, args);
		}

	}
	In app.properties for discovery service (We dont want server to register as a client)
	eureka.instance.hostname=localhost
	eureka.client.register-with-eureka=false
	eureka.client.fetch-registry=false
	server.port=8761
	
	For the client pom
		<dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
        </dependency>
		
	In client app properties
		eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka
		spring.application.name=order-service
	EnableEurekaClient is deprecated, no need to annotate the main class.
	It is enough to add the spring-cloud-starter-netflix-eureka-client dependency to pom.xml and if we have the application name in yml or properties file it will be registered to Eureka Server.	
	See all services
		http://localhost:8761/
		Application	AMIs	Availability Zones	Status
		INVENTORY-SERVICE	n/a (1)	(1)	UP (1) - LAPTOP-KQ6C3UTQ:inventory-service:8082
		ORDER-SERVICE	n/a (1)	(1)	UP (1) - LAPTOP-KQ6C3UTQ:order-service:8081
		PRODUCT-SERVICE	n/a (1)	(1)	UP (1) - LAPTOP-KQ6C3UTQ:product-service
	To be assigned random port
		Provide port as 0 for inventory service..
		Spring Boot at the time of starting up, will assign random free port in the machine and will run inventory service application in that port 
		server.port=0	
		Allow multiple instances in Eclipse Run Configurations
		See 2 availability zones
		Console log
		2023-07-12T19:33:59.099-04:00  INFO 15052 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 58875
		Discovery server
		Application	AMIs	Availability Zones	Status
		INVENTORY-SERVICE	n/a (2)	(2)	UP (2) - LAPTOP-KQ6C3UTQ:inventory-service:8082 , LAPTOP-KQ6C3UTQ:inventory-service:0
		ORDER-SERVICE	n/a (1)	(1)	UP (1) - LAPTOP-KQ6C3UTQ:order-service:8081
		PRODUCT-SERVICE	n/a (1)	(1)	UP (1) - LAPTOP-KQ6C3UTQ:product-service
	#Now replace hardcoded inventory service port and ip in order service
		  InventoryResponse[] inventoryResponses=webClient.get().uri("http://inventory-service/api/inventory",
                uriBuilder -> uriBuilder.queryParam("skuCode",skuCodes).build())
                .retrieve().bodyToMono(InventoryResponse[].class)
                .block();
	#Now test order API 
		Error because there are 2 instances and it doesnt know which one to connect to
		{
			"timestamp": "2023-07-12T23:43:40.855+00:00",
			"status": 500,
			"error": "Internal Server Error",
			"message": "Failed to resolve 'inventory-service' [A(1)] after 2 queries ",
			"path": "/api/order"
		}
	#Client side load balancing should be enabled and order service should try inventory service to try one by one	
		whenever you are creating an instance of your client, you will automatically create the client side load balancer 
		and use the client side load balancing to create the order service while constructing the web client bean
		public class WebClientConfig {
		@Bean
		@LoadBalanced
		public WebClient.Builder webClient(){
			return WebClient.builder();
		}
		}
	#OrderService
	   private final WebClient.Builder webClientBuilder;
	   InventoryResponse[] inventoryResponses=webClientBuilder.build().get().uri("http://inventory-service/api/inventory",
                uriBuilder -> uriBuilder.queryParam("skuCode",skuCodes).build())
                .retrieve().bodyToMono(InventoryResponse[].class)
                .block();
	 #Go To postman and run this on Json	
		{
	   "orderLineItemsDtoList":[
		   {
			   "skuCode":"iphone_13",
			   "price":1200,
			   "quantity":1
		   }
	   ]    
	}		
	After this order placed successfully			
		#Now put discovery Server down and try again
			It succeeds because when client makes a call to discovery server, it gets a local copy of service registry
			Hence it is still able to make that connection (until those local copies are still working)..if they are down, then it will contact discovery server and go down
#ApiGateway
	Microservice environment can have multiple instances and an app can run on different ports
	We cannot rely on harcordedip:port to call the service (external use)
	Use a component at the start of architectural landscape called API gateway which is responsible for routing the request from users to corresponding services
	onlineshop.com(api-gateway) ../.api/product-->then route it to product service /api/order-->go to order server
	Can also configure a rule for accessing eureka service
	Thus it acts as a gatekeeper for whatever request user wants to make to our system
	Can also help with
	--Authentication (Can contact authorisation server or whatever authentication mechanism implemented - talk to keycloak authorization server)
	--Security
	--LoadBalancing
	--SSL Termination (terminated at the entry point of request.. and internally it will use http request)
	#SpringCloudGateway
	Create a module with
	<dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-gateway</artifactId>
     </dependency>
	 Register the API gateway to discovery server
		eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka
	 In app.properties for api-gateway enable more logging
		logging.level.root=INFO
		logging.level.org.springframework.cloud.gateway.route.RouteDefinitionLocation=INFO
		logging.level.org.springframework.cloud.gateway= TRACE
	Define route, predicate and filter	(will do loadbalancing with lb)
	#Product Service Route
	spring.cloud.gateway.routes[0].id=product-service
	spring.cloud.gateway.routes[0].uri=lb://product-service  
	spring.cloud.gateway.routes[0].predicates[0]=Path=/api/product
	#Order Service Route
	spring.cloud.gateway.routes[1].id=order-service
	spring.cloud.gateway.routes[1].uri=lb://order-service
	spring.cloud.gateway.routes[1].predicates[0]=Path=/api/order
	#Inventory Service Route
 By default API gateway runs on port 8080
	#Test with product service
	http://localhost:8080/api/product
	Response
	[
    {
        "id": "649df993b76b9a7e7b956045",
        "name": "Iphone 13",
        "description": "prakash@gmail.com",
        "price": 1200
    }
	]
#See log in API gateway
	2023-07-12T20:45:18.110-04:00 DEBUG 23740 --- [ctor-http-nio-3] o.s.c.g.h.RoutePredicateHandlerMapping   : Mapping [Exchange: GET http://localhost:8080/api/product] to Route{id='product-service', uri=lb://product-service, order=0, predicate=Paths: [/api/product], match trailing slash: true, gatewayFilters=[], metadata={}}

	2023-07-12T20:47:07.188-04:00 DEBUG 23740 --- [ctor-http-nio-3] o.s.c.g.h.RoutePredicateHandlerMapping   : Mapping [Exchange: POST http://localhost:8080/api/order] to Route{id='order-service', uri=lb://order-service, order=0, predicate=Paths: [/api/order], match trailing slash: true, gatewayFilters=[], metadata={}}
	2023-07-12T20:47:07.188-04:00 DEBUG 23740 --- [ctor-http-nio-3] o.s.c.g.h.RoutePredicateHandlerMapping   : [9418209a-2] Mapped to org.springframework.cloud.gateway.handler.FilteringWebHandler@2067b9d1

#Also have eureka server pointed by Api gateway
	#Discovery Service Route
	spring.cloud.gateway.routes[2].id=discovery-server
	spring.cloud.gateway.routes[2].uri=http://localhost:8761
	spring.cloud.gateway.routes[2].predicates[0]=Path=/eureka/web
	spring.cloud.gateway.routes[2].filters[0]=SetPath=/
	localhost:8080/eureka/web should give us discovery information.. however.. because of routing it takes you to 8761/eureka/web when you really just need 8761
		So use a filter	setPath... forward the location to route+set path
		Remove lb in routes
	#Now opens up
		http://localhost:8080/eureka/web
		Comes up without css
	#Only dynamic resources are loaded, for static resources we need more
	
	#Discovery Service Static Resources Route
	spring.cloud.gateway.routes[3].id=discovery-server-static
	spring.cloud.gateway.routes[3].uri=http://localhost:8761
	spring.cloud.gateway.routes[3].predicates[0]=Path=/eureka/**	
	
	Now it comes up properly css is loaded correctly
#Secure microservices using keycloak through API gateway	
	#SpringSecurity
		Secure services /API end points through auth server such as keycloak. Through keycloak we can outsource our authentication and authorization relation configs to keycloak
		Dont need to implement authentication mechanism by hand in our microservices
		Access google or facebook images (connect) from lets says bumble..cannot just give username and password because the app may store this information
		and if a hacker gets access to app db , the accounts will be compromised
	#OAuth.. A stands for authorization	Open Authorization
		Standard way of providing authorization from service 1 to access another service 2
		It will asked to login into google account.. once you login google will ask you what you want to share..after selecting
		google will store it and send token to service 1..
		This token will now be utilized by service 1 to make access requests to service 2 (google).. token will be verified by google
		Change the settings in google account if you want to remove access
		Token
			Random alphanumeric string generated by resource service and passed to client to be able to access resource
			Client uses this to make request	
		Resource
			Things that need to be accessed( google pics)
		(1)Resource Owner
			Person who owns the resource
		(3)Resource Server
			Stores /host resource( google drive server)
			
		(4)Client
			Image gallery application.. that needs access to resource in a resource server
			Public Client
			Confidential Client
			Client must hold the appropriate access token
		(2)Authorization Server
			Receives token requests  from client and upon succesful authentication and consent by resource owner
			Generates access token for clients(AWS Cognita, Okta, Key Cloak--open source, Spring working on its Auth Service offering)
		OIDC
			Open Id connect provides authentication
			Build on top of OAuth2.. email firstname, lastname//2 tokens...Id token --verify user information and identity of user & access token
		Key Cloak
			Docker can be used.. it will run as a container and you can access the port
			Port 8180
			Set JAVA_HOME
			Go to C:\Users\saura\keycloak-22.0.0\keycloak-22.0.0\bin and .\kc.bat start-dev --http-port=8180
			http://localhost:8180/ user:root pass: pass
			Create admin
			Users in one realm are isolated from users in another realm
			First create a realm
				You can group all your oauth2 clients in a single logical entity called realm
				By default keycloak provides a master realm
				oauth-demo-real
				spring-boot-microservices-realm
				Now go to the realm and create your client	
			Client
				Create spring-cloud-client
				Client authentication on and click on service account roles. Disable standard flow & Direct access grants
				After saving , go to client secret
				Go to realm settings
					get the open id configuration and from that the issuer
					issuer:http://localhost:8180/realms/spring-boot-microservices-realm
					We are going to configure this in our API gateway so it can talk to keycloak server
				# not sure...oauth2-demo-thymeleaf-client
						valid redirect uri: http://localhost:8080/login/oauth2/code/oauth2-demo-thymeleaf-client
						default redirect uri: spring boot will automatically recognize
						Whenever you go to localhost:8080/home... spring boot security will redirect you to keycloak login page.. add username and password
						//access token and id token
						spring-cloud-client# not sure
						User
						Add name 
			Spring starter dependencies in api-gateway project
				<dependency>
					<groupId>org.springframework.boot</groupId>
					<artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
				</dependency>
				<dependency>
					<groupId>org.springframework.boot</groupId>
					<artifactId>spring-boot-starter-security</artifactId>
				</dependency>
			#app.properties
				Api gateway will talk to keycloak authentication server
				Just configure the issuer UI and springboot will read the open id configuration
				spring.security.oauth2.resourceserver.jwt.issuer-uri=http://localhost:8180/realms/spring-boot-microservices-realm
			#How this will work
				SpringBoot at the time of starting this application will read this discovery document will fetch all endpoints to do the authorization
				and token id endpoint where spring boot can make a call to this token endpoint and verify the token provided in the user request is valid or not
			#config.SecurityConfig inside api gateway project
				@Configuration
				@EnableWebFluxSecurity
				public class SecurityConfig {
					@Bean
					public SecurityWebFilterChain springSecurityFilterChain(ServerHttpSecurity serverHttpSecurity){
						//disable csrf as we are only communicating through rest/postman client
						//exclude eureka calls
						//when we are accessing eureka static resources, we do not want them to be authenticated,,css and java script files
						//for any other calls we want them to be authenticated
						serverHttpSecurity.csrf().disable().authorizeExchange(exchange->exchange.pathMatchers("/eureka/**")
								.permitAll().anyExchange().authenticated()).oauth2ResourceServer(ServerHttpSecurity.OAuth2ResourceServerSpec::jwt);
						return serverHttpSecurity.build();
					}
			#Access the service via postman
				provide a bearer token or jwt token (hit the product service you get 401)		
				keycloak server log
					2023-07-30 09:27:40,030 WARN  [org.keycloak.events] (executor-thread-1) type=LOGIN_ERROR, realmId=34e15427-8cc8-4ffa-8f6c-925767df8df9, clientId=security-admin-console, userId=c05e4bc3-5239-482e-9357-f5ee1a238c31, ipAddress=0:0:0:0:0:0:0:1, error=invalid_user_credentials, auth_method=openid-connect, auth_type=code, redirect_uri=http://localhost:8180/admin/master/console/, code_id=5f614d6c-78fa-4e4f-b4bd-ceb855d371b6, username=root
				
				request token from keycloak by providing our credentials and then we have to provide those credentials to api gateway via our authorisation header and
				type of bearer scheme
				keycloak gives token and then provide that token 
					Authorization
						Type OAuth 2.0	
						Grant Type: Client Credentials
						Access token Url : http://localhost:8180/realms/spring-boot-microservices-realm/protocol/openid-connect/token
						Client id: spring-cloud-client
						Client Secret: Get from keycloak clients
						Client Authentication: send as a basic auth header
						Click on get new access token
						Once you get token, click on use token.. this token now gets saved and everytime you make request it is passed on the header
						Now if you hit product service , you get response 200 OK
		#For Eureka server
			Cannot use authentication mechanism for connecting eureka service through the browser
		#SpringSecurity
			@EnableWebSecurity
			public class WebSecurityConfig{
				@Bean
				public PasswordEncoder passwordEncoder(){
					return new BCryptPasswordEncoder(strength=11)
				}
			}
			In your user bean	
					passwordEncoder.encode(userModel.getPassword())
			
			User Entity
			Verification Token Entity
			ApplicationEventPublisher(publisher.publishEvent())
			ApplicationListener (onApplicationEvent)
			ApplicationEvent
				Why do we need token?
					When user event application event publisher will pubblish event,, user & appUrl
					Listener will listen, get user, create a token and save it in the db
					same token will be sent by the controller to the user in the email appended to the app url	
					This is to authenticate the email
					
				Create a verify Token with @RequestParam(token).. this is when the user clicks the app url with token
					extract the token ... from the token get the VerificationToken Bean & get user.. get the expiration timestamp 
					and authenticate the user
				Resend email	
					
			Whitelist API for eg login page	
				SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception{
				http
				.cors()
				.and()
				.csrf()
				.disable()
				.authorizeHttpRequests()
				.antMatchers(WHITE_LIST_URL)
				.permitAll()
			return http.build()
			}
			
					
					
				
#Circuit breaker
	Resilient communication between our services in a webclient sync communication
	Synchronous communication.. inventory service maybe down... inventory service may respond slowly.. to the order issue..
	Dont want the request to terminate abruptly
	Failfast and be resilient and we should have some kind of Fallback mechanism
	Circuit breaker :set of states we maintain in our application
		Default : Closed state
				: Open state(throw an error message or send the cached response) and not allow the calls from order service to inventory service for a fixed period of time
				: After some duration the circuit breaker will change the status to half open(sslowly start taking request to inventory service) and it will check if request    
				  are going through. If so it will make the status as closed, if not it will change it back to open
	#Resilience 4j (netflix hystrix)
		Implementation for circuit breaker logic.. easy to use light weight fault tolerance library..newer alternate to (netflix hystrix)
	#SpringDependency
		<dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-circuitbreaker-resilience4j</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>
	#Circuit Breaker
	management.health.circuitbreakers.enabled=true
	management.endpoints.web.exposure.include=*
	management.endpoint.health.show-details=always
	#Resilience4jProperties
		resilience4j.circuitbreaker.instances.inventory.registerHealthIndicator=true
		resilience4j.circuitbreaker.instances.inventory.event-consumer-buffer-size=10
		resilience4j.circuitbreaker.instances.inventory.slidingWindowType=COUNT_BASED
		resilience4j.circuitbreaker.instances.inventory.slidingWindowSize=5
		resilience4j.circuitbreaker.instances.inventory.failureRateThreshold=50
		resilience4j.circuitbreaker.instances.inventory.waitDurationInOpenState=5s
		resilience4j.circuitbreaker.instances.inventory.permittedNumberOfCallsInHalfOpenState=3
		resilience4j.circuitbreaker.instances.inventory.automaticTransitionFromOpenToHalfOpenEnabled=true
	
		
	#OrderController(same name as property-inventory)
	
	@ResponseStatus(HttpStatus.CREATED)
    @CircuitBreaker(name="inventory", fallbackMethod ="fallbackMethod" )
    public String placeOrder(@RequestBody OrderRequest orderRequest){
        return orderService.placeOrder (orderRequest);
    }
    public String fallbackMethod(OrderRequest orderRequest, RuntimeException exception){
        return "Oops something went wrong, please run after sometime";
    }
	
	http://localhost:8081/actuator/health
   // Status is closed	{"status":"UP","components":{"circuitBreakers":{"status":"UP","details":{"inventory":{"status":"UP","details":{"failureRate":"-1.0%","failureRateThreshold":"50.0%","slowCallRate":"-1.0%","slowCallRateThreshold":"100.0%","bufferedCalls":0,"slowCalls":0,"slowFailedCalls":0,"failedCalls":0,"notPermittedCalls":0,"state":"CLOSED"}}}}
  #Now StopInventoryService- Call API 5 times.. you get fallback message from the fallback method
	Circuit breaker State changes to open
  {"status":"UP","components":{"circuitBreakers":{"status":"UNKNOWN","details":{"inventory":{"status":"CIRCUIT_OPEN","details":{"failureRate":"100.0%","failureRateThreshold":"50.0%","slowCallRate":"0.0%","slowCallRateThreshold":"100.0%","bufferedCalls":5,"slowCalls":0,"slowFailedCalls":0,"failedCalls":5,"notPermittedCalls":0,"state":"OPEN"
		
	After 5 seconds(based on properties in app.properties) it changes to half open	{"status":"UP","components":{"circuitBreakers":{"status":"UNKNOWN","details":{"inventory":{"status":"CIRCUIT_HALF_OPEN","details":{"failureRate":"-1.0%","failureRateThreshold":"50.0%","slowCallRate":"-1.0%","slowCallRateThreshold":"100.0%","bufferedCalls":0,"slowCalls":0,"slowFailedCalls":0,"failedCalls":0,"notPermittedCalls":0,"state":"HALF_OPEN"}	

	Now run inventory service.. 
		Place API it succeeds and circuit breaker gets closed
	
	#Simulate slow response (Make timeout in 3 secs where inventory service will take 10 seconds because of thread wait)
		#Resilience4J Timeout Properties
			resilience4j.timelimiter.instances.inventory.timeout-duration=3s
	
	    @TimeLimiter(name="inventory")
		public CompletableFuture<String>  placeOrder(@RequestBody OrderRequest orderRequest){
         return CompletableFuture.supplyAsync(()->orderService.placeOrder (orderRequest));
		}
		public CompletableFuture<String> fallbackMethod(OrderRequest orderRequest, RuntimeException exception){
			return CompletableFuture.supplyAsync(()->"Oops something went wrong, please run after sometime");
		}
	#Simulate wait in inventory service
		 @SneakyThrows
		public List<InventoryResponse> isInStock(List<String> skuCode){
        log.info("Wait started");
        Thread.sleep(10000);
        log.info("Wait ended");
		}
		Within 3 seconds, order service timeouts	
	#Simulate Retry
		#Resilience4J Retry Properties
			resilience4j.retry.instances.inventory.max-attempts=3
			resilience4j.retry.instances.inventory.wait-duration=5s
		One API request will retry 3 times
		http://localhost:8081/actuator/timelimiterevents
		Shows information about no of retries made
		

#Implement Distributed Tracing
4:21:00
	In a production grid application we can have 1000 of log entries for a microservices architecture it will be diffucult to scan through logs
	Helps to trace a request from start to finish so if request is failed any point of time why it failed and where it failed 
	Use trace id-›unique specific for a request, span Id-›no of trips the request made through the system(a unique id for a given request inside each system..span1, span2, span 3)   
	Essentially trace id has multiple span id's
	
	
	#micrometer tracing dependency 
		micrometer-tracing-bridge-brave 
	#zipkin visualize this information 
		zipkin-reporter-brave 
	#Old
	<dependency>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-cloud-starter-sleuth</artifactId>
	</dependency>
	<dependency>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-cloud-sleuth-zipkin</artifactId>
	</dependency>
		
	#new
	<dependency>
      <groupId>io.micrometer</groupId>
      <artifactId>micrometer-tracing-bridge-brave</artifactId>
    </dependency>
    <dependency>
      <groupId>io.zipkin.reporter2</groupId>
      <artifactId>zipkin-reporter-brave</artifactId>
    </dependency>

Add dependency in all services 
	Download Docker zipkin.io Quickstart 
	docker compose up -d
	
  ## Zipkin docker compose
  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    ports:
      - "9411:9411"
	
	Once you add the dependenct by default due to spring auto configuration, all logs will go to localhost:9411
	#For API gateway configure zipkin in app.properties 
		#Zipkin configuration
		management.zipkin.tracing.endpoint=http://localhost:9411/api/v2/spans
		management.tracing.sampling.probability=1.0
		logging.pattern.level=%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]
		
			--(We want to send 100% of request to zipkin) 
		Paste in all services 
	#Once you start services 
		INFO [product-service, traceId, spanId] 
		
	#ZipkinUI 
	
	CircuitBreaker creates a new Thread? Thats why you didnt see a call to inventory service.. Disable circuit breaker and you can see all 3 requests in one go	
	If you are using one thread, you will see the requests from start to end 
	To create your own span id's 
	private final Tracer tracer.nextSpan(). name ("Inventory service lookup") try (tracer.WithSpan (inventoryServiceLookup, start ()) { 
	Span id name was the text given? 


#Event driven architecture in microservice	
	Using kafka 3
	2 Services
		Zookeeper is used to orchestrate the kafka clusters
			#DockerCompose
			zookeeper:
				image: confluentinc/cp-zookeeper:7.0.1
				container_name: zookeeper
				ports:
				  - "2181:2181"
				environment:
				  ZOOKEEPER_CLIENT_PORT: 2181
				  ZOOKEEPER_TICK_TIME: 2000
	
			  broker:
				image: confluentinc/cp-kafka:7.0.1
				container_name: broker
				ports:
				  - "9092:9092"
				depends_on:
				  - zookeeper
				environment:
				  KAFKA_BROKER_ID: 1
				  KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
				  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
				  KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
				  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
				  KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
				  KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1				

	#Spring-Boot with Kafka in order-service and notification-service pom
		 <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artif	actId>
        </dependency>
	#In orderservice application.properties 
		spring.kafka.bootstrap-servers=localhost:9092
	#OrderService (KafkaTemplate clas)
		private final KafkaTemplate<String,OrderPlacedEvent> kafkaTemplate;
		kafkaTemplate.send("notificationTopic",new OrderPlacedEvent(order.getOrderNumber()));
	#CreatedAnOrderPlacedEvent pojo for putting that object in queue rather than simply orderNumber
		For setting default Kafka topic ..put below in app.properties
		spring.kafka.template.default-topic=notificationTopic
	#Value Serializer
		spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
		spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
		Accept bytes as input from producers and sends bytes as outputs to consumers
		We perform serialization-transform object/data into bytes
		They are used into value and key
		Key=123; Value="Hello World" KeySerializer=IntegerSerializer and Value serializer= StringSerializer
		Common serializer->Int,Float String, Avro,ProtoBuf
	#CombiningAllProperties
		#KafkaProperties
		spring.kafka.bootstrap-servers=localhost:9092
		spring.kafka.template.default-topic=notificationTopic
		spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
		spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer		spring.kafka.producer.properties.spring.json.type.mapping=event:com.shopping.orderservice.event.OrderPlacedEvent
	#NotificationService
		@SpringBootApplication
		@Slf4j
		public class NotificationServiceApplication {
			public static void main(String[] args) {
				SpringApplication.run(NotificationServiceApplication.class, args);
			}

			@KafkaListener(topics="notificationTopic")
			public void handleNotification(OrderPlacedEvent orderPlacedEvent){
				//send out email Notification
				log.info("Received notification for order "+orderPlacedEvent.getOrderNumber());
			}
		}
		#Recreate OrderPlacedEvent class in notificaton servicee
		#application.properties
			server.port=0
			eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka
			spring.application.name=notification-service
			#Kafka
			spring.kafka.bootstrap-servers=localhost:9092
			spring.kafka.template.default-topic=notificationTopic
			spring.kafka.consumer.group-id=notificationId
			spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
			spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
			spring.kafka.producer.properties.spring.json.type.mapping=event:com.shopping.notificationservice.event.OrderPlacedEvent
		SpringBoot will understand what is the jsonType mapping by providing the fully classified class name
	#TrustIssue
		spring.kafka.consumer.properties.spring.json.trusted.packages=*
	#
	2023-07-13T00:53:12.214-04:00  INFO 28896 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : notificationId: partitions assigned: [notificationTopic-0]
	2023-07-13T00:53:47.300-04:00  INFO 28896 --- [ntainer#0-0-C-1] c.s.n.NotificationServiceApplication     : Received notification for order efb6fb46-c9f0-4ec7-a973-fb4c94a59210
	Asynchronous communication in form of events
	#Docker
		docker compose up -d
		docker logs -f broker
		docker compose down
		docker logs -f prometheus
	
	
#Dockerize the project
		DockerHub where you will push your docker images once you create them in your local	
		first run mvn package
		Create a Dockerfile
			
			FROM openjdk:17
			ARG JAR_FILE=target/*.jar
			COPY ${JAR_FILE} app.jar
			ENTRYPOINT ["java","-jar","/app.jar"]
		
		Using jdk instead of jre..
		Build the whole image one more time even if you change
		Use layered approach..it will build only files will be changed..save build times	
		Use dockered layer file
			FROM eclipse-temurin:17.0.4.1_1-jre as builder
			WORKDIR extracted
			ARG JAR_FILE=target/*.jar
			ADD ${JAR_FILE} app.jar
			RUN java -Djarmode=layertools -jar app.jar extract

			FROM eclipse-temurin:17.0.4.1_1-jre
			WORKDIR application
			COPY --from=builder extracted/dependencies/ ./
			COPY --from=builder extracted/spring-boot-loader/ ./
			COPY --from=builder extracted/snapshot-dependencies/ ./
			COPY --from=builder extracted/application/ ./
			EXPOSE 8080
			ENTRYPOINT ["java", "org.springframework.boot.loader.JarLauncher"]
		
		#commands
		Go to module.'. give a tag and give the location of folder of dockerfile
			 C:\Users\saura\repo\parent-microservices\microservices-new> cd .\api-gateway\
			 C:\Users\saura\repo\parent-microservices\microservices-new\api-gateway> docker build -t apigateway-dockerfile .
		layeredDocker
			 docker build -t apigateway-layered -f Dockerfile.layered .
		You can see size is much less		
		Containers from java application without docker files
		
		#Use Jib
			TBD
			
			
#Spring boot monitoring
	Monitoring in a micro service project across all services using a data source Promotheus (scrap metrics from actuator endpoints and store in memory db) 
	and Graphana (visualization UI dashboard poll promotheus)
	Spring boot actuator will expose metrics through endpoints(jvm endpoints)... 
	Promotheus will poll our spring boot actuator within predefined seconds and store it in the in-memory db 
	The promotheus will act as a data source for Grafana which provides a UI dashboard
	 
	#Spring started dependences
		spring boot actuator 
		micrometer-registry-prometheus 
		<dependency>
		  <groupId>org.springframework.boot</groupId>
		  <artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>
		<dependency>
		  <groupId>io.micrometer</groupId>
		  <artifactId>micrometer-registry-prometheus</artifactId>
		  <scope>runtime</scope>
		</dependency>
	
	Add in the pom-xml for every service 
		#Enable actuator endpoints in all app.properties
				management.endpoints.web.exposure.include=prometheus 
		Now you can access the /actuator/promotheus end point from your service
		You dont need it in order service
		
	#Add prometheus.yml
		different scrape jobs
	global:
		  scrape_interval:     10s
		  evaluation_interval: 10s
	
	Scrape_configs:
	  - job_name: 'product_service'
		metrics_path: '/actuator/prometheus'
		static_configs:
		  - targets: ['product-service:8080']
			labels:
			  application: 'Product Service Application'
	  - job_name: 'order_service'
		metrics_path: '/actuator/prometheus'
		static_configs:
		  - targets: ['order-service:8080']
			labels:
			  application: 'Order Service Application'
	  - job_name: 'inventory_service'
		metrics_path: '/actuator/prometheus'
		static_configs:
		  - targets: ['inventory-service:8080']
			labels:
			  application: 'Inventory Service Application'
	  - job_name: 'notification_service'
		metrics_path: '/actuator/prometheus'
		static_configs:
		  - targets: ['notification-service:8080']
			labels:
			  application: 'Notification Service Application'
	
	Spin up promotheus and grapahana
		as per docker compose orchestration docker-compose.yml add port add volume --›instruct docker to load from promotheus. ml inside docker container depends on business services, (product, inventory) 
		
	#Prometheus Port 9090
	#Graphana Port 3000 
	Volume /grafana/var/lib Link 
	
	Promotheus: http://localhost:9090/	
		 promotheus UI logback events total 
		 Status-›Service Discovery Status-›Targets .
	
	Grafana:http://localhost:3000/login
	type in admin and password 
	Add a data source-›Prometheus--name as promotheus microservices 
	URL http://prometheus:9090

Take existing dashboard configuration	
		https://github.com/SaiUpadhyayula/spring-boot-microservices/blob/part-10/Grafana_Dashboard.json
	Click on Save and Test 
		Create a dashboard 
		Import via panel json
		Choose your data source
Import existing configuration--›find a json file Grafana.Json..dashboard..-›import Via panel json test. and your pitotheus dataservices. Switch between services using instance (no hikar1 CP pool for non mysq1 db	

Hibernate
spring.jpa.hibernate.ddl-auto
Hibernate property values are: create, update, create-drop, validate and none:
create – 
	Hibernate first drops existing tables, then creates new tables
update – 
	the object model created based on the mappings (annotations or XML) is compared with the existing schema, 
    and then Hibernate updates the schema according to the diff. It never deletes the existing tables or columns even 
	if they are no more required by the application
create-drop – 
	similar to create, with the addition that Hibernate will drop the database after all operations are completed.
	Typically used for unit testing
validate – 
	Hibernate only validates whether the tables and columns exist, otherwise it throws an exception
none – 
	this value effectively turns off the DDL generation
	
	
@OneToOne(fetch=FetchType.EAGER)
@JoinColumn(name="user_id",
nullable=false,
foreignKey=@ForeignKey(name=))	
Create and load
		FetchType.EAGER and FetchType.LAZY
get returns the object by fetching it from database or from hibernate cache whereas 
load() just returns the reference of an object that might not actually exists, 
it loads the data from database or cache only when you access other properties of the object.

get() loads the data as soon as it’s called whereas load() returns a proxy object and loads data only when 
it’s actually required, so load() is better because it support lazy loading.
Since load() throws exception when data is not found, we should use it only when we know data exists.
We should use get() when we want to make sure data exists in the database.		