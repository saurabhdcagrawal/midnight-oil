Creational Design Pattern
	Prototype: 
	
	
	
	
Data Science
		Science of discovering hidden patterns(trends, cycles, rules, association between attributes, groups in data) from large data sets
		Data sets/Data is usually prepared ->cleansed and structured for the analysis
		Science->  	statistical tools and techniques employed to understand the data and reliability of identified patterns		
						Part of Statistics related to understanding data is called descriptive analytics(spread, shape,structure, mean,distribution, gives vital insights about data)
						Part of Statistics for establishing the reliability of potential patterns identified is called inferential statistics (mean distribution)
		ML is at the intersection of Computer Science, Math & Statistics
		Software development is at the intersection of Computer Science & Business Domain/Knowledge
		Traditional Research is intersection of Business/Domain Knowledge and Math & Statistics
		Data Science lies at the intersection of Computer Science, Math & Statistics & Business/Domain Knowledge				
		Data Science lies at the intersection of Computer Science, Math & Statistics & Business/Domain Knowledge
		Data is the footprints of happenings (natural or human driven) Physical as in files, registers now more digital (browsing, online purchases)
		Data is the raw material that contains information in it as also noise
			Eg Ticket Sales, Survey Data
		Information is processed data 
		OR It is the data plus the meaning of what the data was collected for minus the noise
		Data is the input, Information is the output
		Data is unprocessed but information is processed which is made sense of	
		
Mr JC		
	predict products that can go out of stock
	Forecast sales		
	Dutch programmer Guido van Rossum created python in 1991..200 version 2, 2004 python 3
	3d use programming language
	Python supports NLP, Front end ,back end, all work for data scientists..building ML models
	Syntax is important		

Advantage of Anaconda
	In addition to python, we get a bunch of other tools
	100's of packages for data science, scikit-learn(ML), conda(new packages and manage current packages)
	Way to access jupiter notebooks-->Interactive environment to run python code
	With Anaconda, spin up new packages, different version of python that you can easily toggle
	Anaconda navigator..interact with tools
	Install Anaconda Individual edition
	Environments will show all installed libraries
	Anaconda Navigator->Home->Jupyter Notebook
Jupyter	Notebook
	Run time environment for python..Python code is stored inside jupyter in form of notebooks
	You can save notebooks. Code repository for future reason
	Default extension is .ipnyb
	Cell in a jupiter notebook is where you write code..to execute shift+enter
	Write as a code block or lines of code.. The code block is executed at once
	Kernel->tool which controls computation every time you run
		You can interrupt kernel to stop what is running
		Restart will restart everything
	Edit->Manipulate the cells
	Command mode outside cell.. inside cell you are in edit mode. Some shortcuts do not work in edit mode
	Different type of cells-> Markdown for comments.. shortcuts next to cell type (keyboard)
	Markdown is a piece of text..it wont run.. it is a statement..no calculations will be done..It will create text in your file..nothing is being executed
	Out lines are created by compiler..
	In a code block, the response the code block gives is the last thing that the code block is asked to calculated
	Given a notebook, you can run whatever you want to however you want to.. in any order?
	File type is ipynb..cant open it directly..you need to do it through anaconda navigator->jupyter notebook
	File made in Jupyter can also downloaded as html file ..and you can use it to share.. dont need jupytor notebook for the person who receives in this way

Google Colab(Colaboratory)
	Computation in the cloud..for models
	Notebook automatically saved in google drive
	Many pre installed packages
	!pip list--> shows all packages installed
	Read data by storing in drive
	Work on code(notebook) together.. Easy to share the work/collaborate
	Mount google drive in google colab
	Both Collab and Jupyter are python notebook based IDE's
	+Code to add code cell
	+Text to add text cell
	Both in Colab and Jupyter for markdown/text # at the start of cell is used to create different levels of headers such as header, sub-header(##), sub-sub-header(###) etc
	They allow us formatting, to remove a cluttered look and also to shrink stuff

Python
	Python is a case-sensitive language
	Variables need not be declared in advance in Python. To create a variable, we just assign it a value. 
	First thing in the name of the variable should be a letter (following that can be number or underscore)
	# in code cell makes a comment in python
	For multi-line comments, we can use three quotes.
	'''This is 
		a multiline 
		comment in Python'''
	Functions come with normal parentheses & Array, String Matrices come with square parentheses indicating their location 
	Intialization x=y=z=5
	Evaluation in code cell x o/p 5
	String, float, integer 3 basic data types+ bool+complex
	String
		Single quotes or Double quotes
		type function tells you data-type type(x)
		str1='SA'
		Can multiply and add strings str1*2 o/p	SASA
		str1[1],str1[-1] o/p: Both are A
		str2='Great', str2[0:3] o/p 'Gre'
	Float
		d=1.6e4 type(d) is float
	Complex 
		x=3+4j	type(x)=complex
	boolean
		var1=True
		10>9 o/p True
	Change variable type(Casting)
		float(11) o/p 11.0
		int(11.0) o/p 11
		float('11')-> 11.0 but not advisable 
	Print function
		Persistent command. It tells python when you see print you have to print irrespective of where it is in the line of code
		For string with numbers in the end ;following is the syntax; separateÂ numerical part while printing
		I
			y=15 print("y = ", y) o/p y =  15
		II
			price=40
			print('The price of the mobile is',price,sep='$') o/p The price of the mobile is$40
			#sep can be blank sep=''..then it is forced to give no space
			By default the seperation is one space 
			official: By default, Python considers whitespace as the separator between the different values passed to the print() function. 
			Therefore, the values in the code will be printed with whitespace between the values passed using commas
				print("Sarah's age is",35,"turning 36 soon") o/p: Sarah's age is 35 turning 36 soon
		IV	
			y=15
			print('y = ', y,end='\n\n')
			print(y)
		O/P	
			y =  15
			15
		
		for x in range(4,6):
			for y in range(1,11):
				print('{} * {} = {}'.format(x,y,x*y))
				
		f string
			If number to be printed is in the beginning of string or middle use f string
	Input function
		allows the user to add input to the programming environment
		age = int(input("Please enter age of person: "))
		print(age)
		type(age) 	
	
	Arithmetic Operators
		a+b,a-b,a*b,a%b
		a/b gives float eg: 4/2 =2.0
		a//b gives integer (forces) 3//4 0 ---floor division operator.
		a**b gives a raised to the power of b
		concatentation with strings and numbers with +
		Eg 'hello'+'world' is valid but not 'hello'+5 gives error 
			Use explicit conversion: 'hello'+str(5)
			float*int will give float .. (implicit type conversion)	
			
		a=['2','2','2']
		a*2 o/p:['2','2','2','2','2','2']	
		addition of 2 lists with concatenate the list
	Comparison Operators
		O/p of comparison operation is bool -> True or False
		a>b,a>=b,a<b,a<=b,a==b,a!=b
		2.0==2 o/p True
	Assignment Operators eg a+=5
	Logical Operators (and, or)
		x=12
		a=x>5 and x<15
		print(a) o/p->True
		b=x>20 or x<15
		print(b) o/p-> False
		
	range
		range(5) start at 0 and stop before 5.. like a hidden data type unless you explictly force it
		print(range(5)) o/p range(0, 5)
		list(range(5)) o/p [0, 1, 2, 3, 4]
		list(range(6,15,3)) o/p [6, 9, 12]
		for i in range(6,15,3):
			print (i)
	
Data Structures
	List
		List is a list of name and numbers[]
		In Python, List is a collection of objects
		Nested list 
		newList=[1,2,['a','b','c'],5]
		newList[2][1] o/p 'b'
		newList[2][-1] o/p 'c'
		List can contain any data type or combination of data types
		Can identify Strings as list and can do list operations
		strVar='Saurabh'
		strVar[2] o/p 'u'
		Functions to use min,max,len
	Slicing
		Slicing creates a new List
		list[startIndex:stopIndex:step].. Indexes start from 0, start at startIndex, stop before stopIndex..increment with step
		strList=['data science','machine learning','python','html','big data']
		strList, strList[:] prints everything
		strList[:3],strList[0:3] prints first 3 elements starting from 0
		strList[3:] o/p ['html', 'big data']
		strList[1:4:2]  o/p ['machine learning', 'html']
	Mutability
		strList[3]='R'
		strList o/p: ['data science', 'machine learning', 'python', 'R', 'big data']
	List Methods
		Set of methods that can be applied to an object..built in function that applies to a particular kind of object	
		append
			strList.append('html')
			newList=['statistics']
			strList.append(newList)
			strList o/p ['data science','machine learning','python','R','big data','html',['statistics']] (creates a new list)
		insert
			strList.insert(1,'AI') o/p ['data science','AI','machine learning','python','R','big data','html',	['statistics']]
		extend by appending new list
			strList.append(newList) o/p ['data science', 'machine learning', 'python', 'R', 'big data', 'statistics'] (does not create a new list)
		del operator in python del
			Not a method or a function
			del strList[3] remove the 4th element (0-3)
		remove
			no location specified
			strList.remove('R') removes the first occurence of R
		pop
			With no arguments removes the last element
				strList.pop()
			Can also give location
				strList.pop(1)... removes the first element.. uses index when pop
		reverse
			strList.reverse()
		Operators on List
			strList1+strList2 (Simple concatenation)
	
	Tuples(Immutable)
		Order(sequence) is important unlike list
		Like list it also not type checked. It can contain any data type or combination of data types.
		Tuples care abut the sequence in which things are entered into it
		Allow arithmetic calculations to be done in them?
		if only strings then list? but if you want to create objects with numbers inside them for calculation then a tuple is a good construct
		Normal parenthesis to create a tuple()
		Can also create a list inside tuple
		sampleTuple=('a',2,3,['india','asia','japan'])
		type(sampleTuple) o/p tuple
		sampleTuple[0] o/p 'a'
		sampleTuple[0]='b' o/p 'tuple' object does not support item assignment (Immutable)
			if there is a list inside tuple you can change the element inside the list
		del sampleTuple[0]	
			'tuple' object does not support deletion
			
	Tuple methods	
		count 
			Gives the number of times a given value is appearing in the tuple
			sampleTuple=('a',2,3,2,['india','asia','japan'])
			sampleTuple.count(2) o/p 2
		index	
			Ordered collection, so it will tell where a given value is in the tuple-> Gives the first position where the value is present	
			sampleTuple.index(2) o/p 1
		sorted operator (function)
			numberTuple=(5,4,3,2,1)
			sorted(numberTuple) o/p [1, 2, 3, 4, 5]
			however the tuple itself is not sorted as such.. (like in java)..object remains unchanged
			Even Lists can be sorted
		pop		
			Tuples cannot be modified, so the pop() method does not work here. Python will raise an Attribute Error in this case.
		slice
			Tuples can still be sliced to created a new tuple
			X=(20,23,-50,5.6,98)
			print(X[2:-1]) o/p: (-50,-5.6)
	
	Dictionary	
		key value pair. Create using curly braces
		balance={	"Mia":100,
					"John":200,
					"Rajneesh":500
				}	
		Keys need not be strings. It can be anything including numbers
		Values can be complete lists
		Accessing the dictionary (Square brackets)
			balance["Mia"] o/p 100
		Can use get as well (round brace)
			balance.get("Mia")
		Trying to access a key not present gives you key error
			balance["Raj"] o/p KeyError: 'Raj'
		Mutable..can modify the value
			balance["Mia"]=150
				balance o/p {'Mia': 150, 'John': 200, 'Rajneesh': 500}
			if the key is not found, it will be appended
				balance['Saurabh']=0
				balance o/p {'Mia': 150, 'John': 200, 'Rajneesh': 500, 'Saurabh': 0}
		len function 	
			len(balance) o/p 3
			
		popitem()..removes the last item
			balance.popitem()
			balance o/p {"Mia":100,"John":200,"Rajneesh":500}	
		pop(key) removes the key value pair	
			balance.pop("Mia")
			balance o/p {'John': 200, 'Rajneesh': 500}
		Using python's del keyword
			del balance["Mia"]
			balance o/p {'John': 200}
		clear (method for many objects with entries)
			balance.clear()
			balance o/p {}
		create a copy
			balance={"Mia":100,"John":200,"Rajneesh":500}
			copy_dict=balance.copy()
		 
		sorted function in dictionary (sort the keys in the dictionary)	
			numbDict={2:'Sarah',1:'Raj', 5:'Monica'}
			sorted(numbDict) o/p  [1, 2, 5]
		update (same as updating a value directly)
			numbDict.update({2:'Sam'}) 
			numbDict o/p {2: 'Sam', 1: 'Raj', 5: 'Monica'}
			//add a new value
			numbDict.update({7:'Raj'})
			numbDict o/p {2: 'Sam', 1: 'Raj', 5: 'Monica', 7: 'Raj'}	
		keys(), values() method
			Gets the list of keys and values
			a=numbDict.keys()
			b=numbDict.values()
			print(a)	dict_keys([2, 1, 5])
			print(b)	dict_values(['Sarah', 'Raj', 'Monica'])
		
		name_age = {'Jack':20, 'Summer':25, 'June':30}
		//printing dictionaty only print keys
		for i in name_age:
			print(i) 
		o/p (only prints keys)
			Jack 
			Summer
			June	
		
		
balance
	Sets
		Sets are defined with curly braces and stores values without any duplicates in ascending order(Ascending is important)	
		Sequence doesnt matter..,matters less than it matters in a list
		Created using curly braces like dictionary
			s={1,1,1,1,1,1}
			s o/p{1}
		Set operator/function
			returns distinct elements of list
			set({1,2,4,3,3,2,1}) o/p {1, 2, 3, 4}
		Same methods, adding, updating, removal, pop, length


	Conditional Statements
		if condition :
			steps/code to be executed after condition is true 
			myList=['python','datascience','R','spark','Tableau']
			learning='python'
			if learning in myList:
				print(learning+' tutorial')
			else:
				print('Not in my learning')
						
			if not x ==500
				print('the value of x is different from 500')
				
			if (not x ==500):
				print('the value of x is different from 500')	
				
			if (x>500):
				print('Number is greater than 500')
			elif(x>400):
				print('Number is greater than 400')
			else :
				print('Number is less than 400')	
				
			a = "I am a Data Scientist"
			if "Data" in a:
				print("It is present")
			else:
				print(False)	
	
		Nested if 	
			Write a program to i/p a float number and see if its 0, positive or negative		
		
			number = float(input("Enter a number: "))
			if number >= 0:
				if number == 0:
					print('Number is zero')
				else:
					print('Number is greater than zero')
			else:
				print('Number is negative')  
				

	Looping for loops
		for i in range(5):
			print(i)
		Note: no parentheses for for condition	
				
		Write a program to find the sum of numbers in a list
		Note that sumFinal variable used in the loop had to be initialized (because of scope being used outside)
			sumFinal=0
			listVar=[100,220,345,585,645]
			for num in listVar:
				sumFinal += num
			print("sum of numbers is", sumFinal)  
			
		While loops (else is integrated)
		In most of the programming languages, the use of else statement has been restricted with the if conditional statements. But Python also allows us to use the else condition with for loops.
			
			a = 1
			limit = 20
			intSum=0
			while a < limit :
				intSum += a
				a +=1
			else:
				print('Sum is ',intSum)
				
	Break
		Write a program to check a list has even number or not
		For with else integrated..runs afte
			listNum=[3,5,5,55,75,15]
			for i in listNum :
				if(i%2==0):
					print('Even number found', i)
					break
			else:
				print('No even numbers met')
    
	Continue
		Print odd numbers from 5 to 15	
		
			for i in range(5,15):
				if (i%2 == 0):
					continue
				else:
					print(i)
		
	Question is when is why with else or for with else executed.
		if there is no break.
		Essentially else is a part of for ..if it encounters break, it will move out of for and else
		
		for i in range(1, 4):
			print(i)
		else: # Executed
			print("Break executes")
		o/p
		1
		2
		3
		Break executes	
		*** See loop prints in a new line always?	
		for i in range(1, 4):
			print(i)
			break
		else: # Not executed as there is a break
			print("Break does not execute")	
		o/p 1

			
	
	List Comprehension
		List comprehension is a type of control structure for creating a list from an existing iterable (like tuples, strings, arrays, lists, etc).
		They offer a shorter and more appealing syntax and are often faster than explicit for loops in creating a list from an existing iterable.
			apple_prods_price_list=[9000,5666,1254,566,8686]
			
			discounted_price=[]
			for x in apple_prods_price_list:
				discounted_price_val=0.95*x
				discounted_price.append(discounted_price_val)
			discounted_price			
		Now in list comprehension we will write that as	
			discounted_price=[0.95*x for x in apple_prods_price_list]
			discounted_price
		One more
			budget= float(input("Enter your budget for the product:"))
			purchase_possible=['Yes' if x <= budget else 'No' for x in apple_prods_price_list]
			purchase_possible o/p ['No', 'No', 'Yes', 'Yes', 'No']
			
		numbers= range(20)
		even_list = [i**2 if i %2 ==0 for i in numbers]
		even_list	
		
					
		repeated_list = [2] * 4
		print(repeated_list) o/p [2, 2, 2, 2]	
		
		[ ]: The outer square brackets tells that we are creating a list
		x-(x*(5/100): The expression to evaluate or the computation to perform
		for x in price_list: The iterable from which elements (x) will be fetched
		
	Functions
		Reusability of code
			def funcn_name(parameters):
				statement1
				statement2
				...
			Eg
			def add_my_func(a,b):
				print(a+b)
			add_my_func(11,20)
			
		function with a return
			def return_sum_funcn(a,b):
				return a+b
			print(return_sum_funcn(11,20))
			sum_val=sum_funcn(11,30)

		A function can be defined inside another function in Python. The inner function will be then called by the outer function
			def outer_fun(a, b):
				#statements
				def inner_fun(a, b):
					#statements
			# call inner function from outer function
				x = inner_fun(a, b)		
	
	Lambda function
		We generally use them when we require an anonymous function for a small task
		User-defined functions are defined using the def keyword, whereas lambda functions are defined using the lambda keyword.
		We cannot use a return statement with lambda functions
		Syntax func_name=lambda argument:statement
		
		dis_add_funcn = lambda a,b :a+b
		res=dis_add_funcn(15,20)
		res o/p 35
		
		(lambda x: (x+2)*5/2)(4) o/p 15.0
		The parentheses after the lambda function definition containing 4 specify the argument to be passed to the function.
	
	*args in function parameter i/p
		No of arguments is not defined.. we can have any number of arguments..(list of arguments)
		can name it as *prices
		def total_amount(*args):
			total=0
			for arg in args:
				total+=arg
			return total	
		total_amount(12,56,66,44,75) o/p: 253
		
		def fun(*args):return args
		fun(12,34,5) o/p (12,34,5) returns tuple of i/p arguments
		
	kwargs
		def total_discounted_amount(*prices,discount=0.0):
			total=0
			for price in prices:
				total+=price
			discounted_price=total-(total*discount)
			return discounted_price
		
		total_discounted_amount(100,100,100)
		total_discounted_amount(100,100,100,discount=0.5)
		
		Positional arguments & Keyword arguments
		positional come before keyword.. In above.. positional is *prices, keyword one is discount

		def total_discounted_amount(*prices,discount=0.0,**kwargs):
			total=0
			for price in prices:
				total+=price
			discounted_price=total-(total*discount)
			net_spend=discounted_price-kwargs['cashback']
			return net_spend	
			
		total_discounted_amount(100,100,3,discount=0.5,**additionals)	
		
		additionals={'cashback':5}
		total_discounted_amount(100,100,3,**additionals) o/p 198
		
		def fun(A, B=30):
			return A + B
		(A is a positional argument, B is a keyword argument)	
		
		def total_discounted_amount(*prices,discount=0.0,**additionals):
		total=0
		for price in prices:
			total+=price
		discounted_price=total-(total*discount)
		net_spend=discounted_price-additionals['cashback']-additionals['rewards']
		if(net_spend>1000):
			pr_rewards=10
		else:
			pr_rewards=0
		return net_spend,pr_rewards  
		
		additionals={'cashback':5,'rewards':10}
		ns, prr=total_discounted_amount(10000,100,3,discount=0.5,**additionals)
		print('NetSpend',ns,"rewards",prr)
		
		
List of functions glossary
	del dictionary
	len dictionary
	print
	sorted tuple dictionary
   .pop
   .get dictionary
   .copy dictionary
   .update dictionary
   
   sum is a keyword?
   https://medium.com/geekculture/list-comprehension-conditional-and-looping-statements-in-python-16db4ea9e58b
   https://towardsdatascience.com/how-list-comprehensions-can-help-your-code-look-better-and-run-smoother-3cf8f87172ae
   https://colab.research.google.com/notebooks/io.ipynb
	
Numpy
	Numerical Python: package used to do a lot of numerical operations
	Tell Python we have to use numpy 
		import numpy as np
	Numpy has a bunch of functions, data types that we can use . 
	Always import it
	Numpy arrays 
		are more powerful than normal lists
		Like a list
		When you print, no comma between individual values between rows or columns
		numpy arrays are strictly typed
			arr_str=[4,5,6,7]
			np_arr_num=np.array(arr_str)
			np_arr_num
				type: <numpy.ndarray>
			sports = ['Cricket', 'Football', 'Tennis', 'Golf', 'Baseball']
			sports_new = np.array(sports)
			print(sports_new) o/p ['Cricket' 'Football' 'Tennis' 'Golf' 'Baseball']
			sports_new o/p array(['Cricket', 'Football', 'Tennis', 'Golf', 'Baseball'], dtype='<U8')
			Arithmetic operation on arrays
				arr1=np.array([1,3,5,6])
				arr2=np.array([2,2,2,2])
				print(arr1+arr2)
				print(arr1-arr2)
				print(arr1/arr2)
				print(arr1*arr2)
				print(1/arr1) **Not linear algebra division or inverse? Rather element wise inverse division
				print(arr1**arr2)
	Matrix
		2D
		matrix=np.array([[1,1,1],[2,3,4]])
		print(matrix)
		o/p: [[1 1 1]
			[2 3 4]]
		type(matrix)
			<numpy.ndarray>
		matrix
		array([[1, 1, 1],
			 [2, 3, 4]])	
		Arithmetic operation on matrices
			matrix1=np.arange(1,10).reshape(3,3)
			matrix2=np.eye(3)			
			print(matrix1+matrix2)
			print(matrix1-matrix2)
			print(matrix1/matrix2) 
				inf in o.p for infinite
				will give output but with runtime warning
			print(matrix1*matrix2)
			Again this is element and not linear algebra***
			linear algebra multiple multiplication/dot product use @
				print(matrix1@matrix2)
		Transpose
			np.transpose(matrix1)
			matrix2.T #transpose matrix
		Min,Max
			np.min(matrix1)
			np.max(matrix2)
			get the min and max value of a matrix.. single value
	Tensors
		3D,4D,5D
	arange function
		Creates a single dimension array
		arr3=np.arange(start=0, stop=20, step=5)
		arr3 o/p array([ 0,  5, 10, 15])
		arr4=np.arange(0,5)
		print(arr4) o/p: [0 1 2 3 4]
	linspace
		matrix=np.linspace(0,50)
			Creates a 1d array of 50 equidistant points(by default) including last number and first number , because it starts from 0 and ends at 50 there are 2 points
			Rest has to be divided by 49 (50-0)/49
		matrix=np.linspace(1,5,5)
			[1. 2. 3. 4. 5.]
	Zeroes
		matrix=np.zeros([2,3])
	Ones
		matrix=np.ones([2,3])
		matrix
			array([[1., 1., 1.],
				   [1., 1., 1.]])	
	eye
		matrix=np.eye(3)
		Identity matrix
		[[1. 0. 0.]
		 [0. 1. 0.]
         [0. 0. 1.]]	
	reshape	
		arr4= np.arange(0,10)
		arr4_reshaped=arr4.reshape([2,5])
		print(arr4_reshaped) o/p [[0 1 2 3 4]
                                  [5 6 7 8 9]]
		arr4_reshaped=arr4.reshape([2,6])
		ValueError: cannot reshape array of size 10 into shape (2,6)						  
	Trigonometry (in radians)
		np.sin(4),np.cos(4),np.tan(4)
		can give it a numpy array or a list
	exp
		np.exp(2)
	log	
		arr5=np.array([2,4,5])
		np.log(arr5)
		log to the base 10
			np.log10(10)
			np.log2(10)
		For other bases uses formula
		
		
Pandas
	Another library to create datasets and manipulate datasets
		import pandas as pd
	Creates a new datatype like pandas data frame and pandas data series
	Nice way to store and manipulate data in python
	We are going to have our own little excel spreadsheets sitting inside python
	Use this same name to refer functions of this library
	Pandas series
		one column in an excel spreadsheet with row labeling
		Create a list or numpy array into a pandas series	
			med_price_list=[25,50,76,100]
			arr_med_price=np.array(med_price_list)
			series_list=pd.Series(med_price_list)
			series_arr=pd.Series(arr_med_price)
			print(series_list)
				0     25
				1     50
				2     76
				3    100
				dtype: int64
			print(series_arr)	
				0     25
				1     50
				2     76
				3    100
				dtype: int32
			med_price_labeled=pd.Series(med_price_list, index=['Omeprazole','Azithromycin','Metformin','Ibuprofin'])	
			print(med_price_labeled)
				Omeprazole       25
				Azithromycin     50
				Metformin        76
				Ibuprofin       100
				dtype: int64
			med_price_labeled+=2.5
			print(med_price_labeled)
				Omeprazole       27.5
				Azithromycin     52.5
				Metformin        78.5
				Ibuprofin       102.5
				dtype: float64
			new_med_price_list=[78,55,445,239]
			new_med_price_labeled=pd.Series(new_med_price_list, index=['Omeprazole','Azithromycin','Metformin','Ibuprofin'])
			new_med_price_labeled-med_price_labeled
				Omeprazole       50.5
				Azithromycin      2.5
				Metformin       366.5
				Ibuprofin       136.5
				dtype: float64
			Looks like numpy areas with index lables on them
			Indexing &Accessing
				new_med_price_labeled[0]
					78
				new_med_price_labeled[:3]
					Omeprazole       78
					Azithromycin     55
					Metformin       445
					dtype: int64
				new_med_price_labeled[-2:]	(to the end)
					Metformin    445
					Ibuprofin    239
					dtype: int64
				new_med_price_labeled[:-2]	(from the beginning)
					Omeprazole      78
					Azithromycin    55
					dtype: int64
				new_med_price_labeled[[0,2,3]]
					Omeprazole     78
					Metformin     445
					Ibuprofin     239
					dtype: int64
			Labeled index
				new_med_price_labeled['Omeprazole']
					78
				Slicing with label (Python inconsistency, this is inclusive)
					new_med_price_labeled[:'Ibuprofin']
						Omeprazole       78
						Azithromycin     55
						Metformin       445
						Ibuprofin       239
						dtype: int64
	DataFrame
		Real power of pandas package
		sequences or several series put together
		A dataframe is made up of several series where each column is a series.
		Data column has same type
		But different columns may have different data types(like excel)
			student=['Jitin','Minh','Saurabh']
			df=pd.DataFrame(student,columns=['Student'])	
			df
					Student
				0	Jitin
				1	Minh
				2	Saurabh
		With dictionary
			grades=['B-','A+','A-']
			df2=pd.DataFrame({'Student':student,'Grade':grades})
			df2
				Student		Grade
			0	Jitin		B-
			1	Minh		A+
			2	Saurabh		A-
		DataFrame using pd.series
			year=pd.Series([2012,2013,2014,2015])
			energy_consumption=pd.Series([1500,2000,2700,8000])
			energy_df=pd.DataFrame({'Year':year,'Energy Consumption in killowatts':energy_consumption})
			Year	Energy Consumption in killowatts
				0	2012	1500
				1	2013	2000
				2	2014	2700
				3	2015	8000
		Using a matrix from numpy array
			pd.DataFrame(np.random.randn(5,2),columns=['Trial1','Trial2'])
				Trial1		Trial2
			0	-0.212177	-0.121405
			1	0.487844	0.506549
			2	3.897380	1.087862
			3	0.418165	0.157110
			4	1.435211	-1.605930
		Accessing elements of df
			energy_df[0] 
				error
			energy_df[:1]
				Year	Energy Consumption in killowatts
			0	2012	1500
			Access column as data series
				energy_df['Year']
					0    2012
					1    2013
					2    2014
					3    2015
					Name: Year, dtype: int64
				energy_df[::2]
					Year	Energy Consumption in killowatts
				0	2012	1500
				2	2014	2700
				energy_df[::-1] (in reverse)
					negative reverses order
					Year	Energy Consumption in killowatts
				3	2015	8000
				2	2014	2700
				1	2013	2000
				0	2012	1500
		Adding a new column
			energy_df['Region']=['Arkansas','Colarado','Massachusets','New York']
			energy_df
						Year	Energy Consumption in killowatts	Region
					0	2012	1500								Arkansas
					1	2013	2000								Colarado
					2	2014	2700								Massachusets
					3	2015	8000								New York
		Dropping a column from data frame
			energy_df.drop('Region')
				Gives an error because by default axis is 0. It tries to find a row to drop
			energy_df.drop('Region',axis=1)
				Creates a new dataframe where it drops the column
				energy_df.drop('Region',axis=1,inplace=True)
				Drops the column in old dataframe and also creates a new data frame with the dropped column
		Copy a data frame
			new_energy_df=energy_df.copy()
		Dropping a row in data frame
			new_energy_df=energy_df.copy()
			new_energy_df.drop(1,axis=0,inplace=True)
						Year	Energy Consumption in killowatts
					0	2012	1500
					2	2014	2700
					3	2015	8000	
			Index remains modified		
				new_energy_df.reset_index()	
						index	Year	Energy Consumption in killowatts
					0	0	2012	1500
					1	2	2014	2700
					2	3	2015	8000				
				new_energy_df.reset_index(drop=True,inplace=True)
				new_energy_df		
						Year	Energy Consumption in killowatts
					0	2012	1500
					1	2014	2700
					2	2015	8000
		Accessing individual entries or sub entries
			The loc method works on label-based indexing whereas iloc method works based on integer-based indexing.
			First value is integer, second is column name
			energy_df.loc[1]
				Year                                2013
				Energy Consumption in killowatts    2000
				Name: 1, dtype: int64
			energy_df.loc[[1,3],['Year']]
					Year
				1	2013
				3	2015
			iloc
					Year	Energy Consumption in killowatts
				1	2013	2000
				3	2015	8000
			Modifying with loc
				energy_df.loc[3,'Year']
				energy_df.loc[3,'Year']=2017
				energy_df
					Year	Energy Consumption in killowatts
				0	2012	1500
				1	2013	2000
				2	2014	2700
				3	2017	8000
			Modifying with iloc
				energy_df.iloc[3,0]=2015
					Year	Energy Consumption in killowatts
					0	2012	1500
					1	2013	2000
					2	2014	2700
					3	2015	8000
			Condition Based Indexing
				energy_df['Energy Consumption in killowatts']>2000
					0    False
					1    False
					2     True
					3     True
				Name: Energy Consumption in killowatts, dtype: bool
				energy_df.loc[energy_df['Energy Consumption in killowatts']>2000]
					Only return rows that are true
					Year	Energy Consumption in killowatts
				2	2014	2700
				3	2015	8000
		Combining Data frames
		merge() can be used for combining data on common columns
		concat() can be used for combining dataframes across rows or columns
		data_cust = pd.DataFrame({"customerID":['101','102','103','104'], 
								'category': ['Medium','Medium','High','Low'],
								'first_visit': ['yes','no','yes','yes'],
								'sales': [123,52,214,663]},index=[0,1,2,3])

		data_cust_new = pd.DataFrame({"customerID":['101','103','104','105'], 
							'distance': [12,9,44,21],
							'sales': [123,214,663,331]},index=[4,5,6,7])	
		
			customerID	category	first_visit	sales
			0	101	      Medium	 yes	     123
			1	102	      Medium	 no	         52
			2	103	        High	 yes	     214
			3	104	         Low	 yes	     663
			
			customerID	distance	sales
			4	101			12		123
			5	103			9		214
			6	104			44		663
			7	105			21		331
			(Why does it start from 4,5,6,7?)
			
			pd.concat([data_cust,data_cust_new],axis=0)
				NaN is short for not a number
				Just append row.. common columns and rows appened
			customerID	category	first_visit	sales	distance
			0	101		Medium		yes			123			NaN
			1	102		Medium		no			52			NaN
			2	103		High		yes			214			NaN
			3	104		Low			yes			663			NaN
			4	101		NaN			NaN			123			12.0
			5	103		NaN			NaN			214			9.0
			6	104		NaN			NaN			663			44.0
			7	105		NaN			NaN			331			21.0
			
			pd.concat([data_cust,data_cust_new],axis=1)
			all columns are appended to the right	
			None of the series will be on top of each other. Because the series will be combined side-by-side. 
			When axis=0, two series will stack on each other. When axis=1, two series will stack parallel to each other
			Rarely used
			customerID	category	first_visit	sales	customerID	distance	sales
				0	101	  Medium	 yes	    123.0	 NaN	     NaN	     NaN
				1	102	  Medium	 no	        52.0	 NaN	     NaN	     NaN
				2	103	  High	     yes	    214.0	 NaN	     NaN	     NaN
				3	104	  Low	     yes	    663.0	 NaN	     NaN	     NaN
				4	NaN	  NaN	     NaN	    NaN	     101	     12.0	     123.0
				5	NaN	  NaN	     NaN	    NaN	     103	     9.0	     214.0
				6	NaN	  NaN	     NaN	    NaN	     104	     44.0	     663.0
				7	NaN	  NaN		 NaN	    NaN	     105	     21.0	     331.0
				
			Merge (merge the rows)
				pd.merge(data_cust,data_cust_new,how='outer',on='customerID') --outer is the union			
					customerID	category	first_visit	sales_x	distance 	sales_y
					0	  101	Medium	     yes	     123.0	 12.0	    123.0
					1	  102	Medium	     no	         52.0	 NaN	    NaN
					2	  103	High	     yes	     214.0	 9.0	    214.0
					3	  104	Low	         yes	     663.0	 44.0	    663.0
					4	  105	NaN	         NaN	     NaN	 21.0	    331.0
				pd.merge(data_cust,data_cust_new,how='inner',on='customerID') --inner is the intersection			
					customerID	category	first_visit	sales_x	distance 	sales_y
					0	  101	Medium	     yes	     123.0	 12.0	    123.0
					1	  103	High	     yes	     214.0	 9.0	    214.0
					2	  104	Low	         yes	     663.0	 44.0	    663.0
				pd.merge(data_cust,data_cust_new,how='right',on='customerID') --all rows in right		
					customerID	category	first_visit	sales_x	distance 	sales_y
					0	  101	Medium	     yes	     123.0	 12.0	    123.0
					1	  103	High	     yes	     214.0	 9.0	    214.0
					2	  104	Low	         yes	     663.0	 44.0	    663.0
					3	  105	NaN	         NaN	     NaN	 21.0	    331.0
			Join (merge on index values(labels) instead of a column)
				Syntax different.. first_data_frame.join(second_data_frame)
					data_quarters = pd.DataFrame({'Q1': [101,102,103],
                              'Q2': [201,202,203]},
                               index=['I0','I1','I2'])

					data_quarters_new = pd.DataFrame({'Q3': [301,302,303],
                                  'Q4': [401,402,403]},
                               index=['I0','I2','I3'])
					Q1	Q2
				I0	101	201
				I1	102	202
				I2	103	203		
					
				Q3	Q4
				I0	301	401
				I2	302	402
				I3	303	403
				
				data_quarters.join(data_quarters_new,how="inner")
					Q1	Q2	Q3	Q4
				I0	101	201	301	401
				I2	103	203	302	402				
				
		Functions
			energy_df.head()-- first five rows
			energy_df.tail()-- bottom five rows
			energy_df.shape -- rows and column count
				(4, 2)
			energy_df.info()--- to check the data type of columns
				energy_df.head()	
				<class 'pandas.core.frame.DataFrame'>
				RangeIndex: 4 entries, 0 to 3
				Data columns (total 2 columns):
				 #   Column                            Non-Null Count  Dtype
				---  ------                            --------------  -----
				 0   Year                              4 non-null      int64
				 1   Energy Consumption in killowatts  4 non-null      int64
				dtypes: int64(2)
				memory usage: 192.0 bytes
			Min and max of a column	
				energy_df['Energy Consumption in killowatts'].min()	
			Unique values in a column
				energy_df['Energy Consumption in killowatts'].unique()
			value_counts:To check the counts of unique value in a column
				The value_counts() function returns unique values in descending order of number of occurrences, i.e., the first element in the output is the most frequently-occurring element
				energy_df['Energy Consumption in killowatts'].value_counts()
					1500    1
					2000    1
					2700    1
					8000    1
					Name: Energy Consumption in killowatts, dtype: int64
				energy_df['Energy Consumption in killowatts'].value_counts(normalize=True)
					1500    0.25
					2000    0.25
					2700    0.25
					8000    0.25
					Name: Energy Consumption in killowatts, dtype: float64
					Divides by the total counts
			Statistical functions
				energy_df['Energy Consumption in killowatts'].mean()
					3550
				median
				mode
					energy_df['Energy Consumption in killowatts'].mode()[0]
					mode returned is a list since it can be multiple
				
				data_cust.describe()
							sales
					count	4.000000
					mean	263.000000
					std		274.785977
					min		52.000000
					25%		105.250000
					50%		168.500000
					75%		326.250000
					max		663.000000

		Loading and saving data frames
			load csv and excel files from hard drive into pandas
				data=pd.read_csv('/content/music.csv')
			For google colab, we have to give colab access to our google drive
				from google.colab import drive
				drive.mount('/content/drive')
			Once drive is mounted
				path="/content/music.csv"
				data=pd.read_csv(path)
			Save data frame as csv file
				data.to_csv('/content/modified_music.csv',index=False)
				if index is not put to false, then it will add index value as a seperate column 
			Save data frame as excel file
				data.to_excel('/content/modified_music_excel.xsls',index=False)
		groupby
			splits the data into groups based on some criteria
			applies a function to each category
			combines the result based on the applied function
				data=pd.read_csv('StockData.csv')
				data.groupby(['stock'])['price'].mean()
		apply
			The apply() function can be used in both series and dataframe. 
			It is used to apply a function along an axis of the Dataframe.		
				def profit(s):
						return 1.10*s
					data['new_price']=data['price'].apply(profit)
		sort_values
			data.sort_values(by='new_price',ascending=False)
			By default ascending is true
					stock			date	price	new_price
			1244	AAPL	18-01-2018	179.26	197.186
			1243	AAPL	17-01-2018	179.10	197.010
			1245	AAPL	19-01-2018	178.46	196.306
			1241	AAPL	12-01-2018	177.09	194.799
			1247	AAPL	23-01-2018	177.04	194.744
			